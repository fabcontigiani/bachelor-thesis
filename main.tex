% Tipo de documento y márgenes
\documentclass[a4paper, 12pt]{report}
\usepackage[top=3cm, bottom=3cm, left = 2cm, right = 2cm]{geometry}

% Codificación y lenguaje
\usepackage[utf8]{inputenc}
\usepackage[spanish,es-tabla]{babel}
\usepackage{csquotes}

% Imágenes
\usepackage{graphicx}
\usepackage[labelfont=bf]{caption}
\usepackage{subcaption}

% Tablas
\usepackage{tabularray}

% Gráficos
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% Código fuente
\usepackage{listings}
\usepackage{xcolor}

% Colores para syntax highlighting
\definecolor{codegreen}{rgb}{0.2,0.6,0.2}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{codeblue}{rgb}{0.0,0.4,0.7}
\definecolor{backcolour}{rgb}{0.97,0.97,0.97}

\lstset{
	basicstyle=\ttfamily\footnotesize,
	backgroundcolor=\color{backcolour},
	commentstyle=\color{codegreen}\itshape,
	keywordstyle=\color{codeblue}\bfseries,
	stringstyle=\color{codepurple},
	numberstyle=\tiny\color{codegray},
	numbers=left,
	stepnumber=1,
	numbersep=5pt,
	frame=lines,
	breaklines=true,
	breakatwhitespace=true,
	tabsize=4,
	showstringspaces=false,
	captionpos=b,
	language=C
}
\renewcommand{\lstlistingname}{Código}
\renewcommand{\lstlistlistingname}{Índice de códigos fuente}

% Bibliografía
\usepackage[nottoc]{tocbibind}
\usepackage[style=ieee, backend=biber]{biblatex}
\addbibresource{referencias.bib}

% Links
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=black,citecolor=black,urlcolor=blue}

% Glosario
\usepackage{datatool}[=v2.32]
\usepackage[toc,acronym]{glossaries}
\setacronymstyle{long-short}
\makenoidxglossaries
\loadglsentries{glosario}

% Unidades
\usepackage[locale=DE]{siunitx}

\title{Sistema de Monitoreo y Alerta Temprana basado en Inteligencia Artificial
para Áreas Protegidas}
\author{Autores:\\Fabrizio Martin Contigiani\\Gabriel Orlando Da
Silva Schmies \\\\Tutor:\\Dr. Ing. Sergio Eduardo Moya}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
	\hspace{1.5em}El presente trabajo describe el diseño e implementación de un sistema
	de monitoreo y alerta temprana para áreas protegidas de la
	\gls{selva-misionera}, que combina tecnologías de \gls{iot} con \gls{ia}
	para la detección automática de fauna silvestre, personas y vehículos.

	El sistema está compuesto por una red de \glspl{nodo} de captura basados en
	microcontroladores \gls{ESP32} equipados con cámaras, los cuales se comunican
	mediante el protocolo \gls{ESP-MESH} para transmitir imágenes hacia un
	\gls{nodo-raiz}. Este nodo actúa como puerta de enlace, reenviando las imágenes
	a un servidor remoto a través de \gls{tcp}/IP.

	En el servidor, las imágenes son procesadas por un servicio de
	\gls{inferencia} basado en \gls{speciesnet}, un modelo de detección de objetos
	desarrollado por Google que utiliza \gls{yolov5}. Este modelo permite
	identificar y clasificar especies de fauna silvestre, así como detectar
	la presencia de humanos y vehículos, generando alertas automáticas
	ante posibles intrusiones.

	La arquitectura del servidor incluye una aplicación web desarrollada
	en \gls{django} para la gestión de imágenes, un \gls{telegram-bot} para el
	envío de notificaciones en tiempo real, y una base de datos \gls{postgresql}
	para el almacenamiento persistente. Todo el sistema está
	contenedorizado mediante \gls{docker} para facilitar su despliegue.

	Los resultados demuestran la viabilidad de implementar un sistema de
	vigilancia inteligente de bajo costo para áreas protegidas, capaz de
	operar de manera autónoma y alertar a los administradores ante
	eventos relevantes.

	\vspace{2em}
	\noindent\textbf{Palabras Clave} - Cámaras Trampa, Internet de las Cosas,
	Inteligencia Artificial, Monitoreo de Fauna, Detección de Intrusos,
	ESP-MESH, SpeciesNet, Selva Misionera
\end{abstract}

\tableofcontents

\listoffigures

\listoftables

\lstlistoflistings
\addcontentsline{toc}{chapter}{\lstlistlistingname}

\printnoidxglossary[type=main]
\printnoidxglossary[type=\acronymtype]

% ==============================================================================
% Capítulo 1: Introducción
% ==============================================================================
\chapter{Introducción}

La conservación de la fauna silvestre y la protección de áreas naturales
representan desafíos críticos en la actualidad. En regiones de alta
biodiversidad como la \gls{selva-misionera}, la pérdida de hábitat,
la \gls{caza-furtiva} y la intrusión humana en ecosistemas protegidos amenazan
el equilibrio ecológico y la supervivencia de numerosas especies. Ante
esta problemática, surge la necesidad de implementar sistemas de monitoreo
que permitan vigilar estas áreas de manera continua y eficiente.

Tradicionalmente, el monitoreo de fauna silvestre se ha realizado mediante
\glspl{camara-trampa}, dispositivos que capturan imágenes cuando detectan
movimiento. Sin embargo, estos sistemas convencionales presentan limitaciones
significativas: requieren revisión manual periódica, no permiten alertas
en \gls{tiempo-real}, y generan grandes volúmenes de datos que deben ser
analizados manualmente por expertos.

El avance de tecnologías como el \gls{iot} y la \gls{ia} ofrece nuevas
posibilidades para superar estas limitaciones. La combinación de redes
de sensores inalámbricos con algoritmos de \gls{deteccion-objetos} permite
desarrollar sistemas capaces de identificar automáticamente fauna silvestre,
personas y vehículos, generando alertas inmediatas ante eventos relevantes.

El presente trabajo, desarrollado en el marco de la Universidad Nacional
de Misiones, propone el diseño e implementación de un sistema de
monitoreo y alerta temprana para áreas protegidas de la región, que integra una red
de nodos de captura basados en \gls{ESP32} comunicados mediante \gls{ESP-MESH},
un servidor de procesamiento con \gls{ia} basado en \gls{speciesnet}, y
un sistema de notificaciones a través de \gls{telegram-bot}.

\section{Contexto y motivación}

Las áreas protegidas enfrentan amenazas constantes que van desde la caza
ilegal de especies en peligro hasta la intrusión de personas no autorizadas
y vehículos en zonas restringidas. Los guardaparques y administradores
de estas áreas frecuentemente carecen de los recursos humanos y tecnológicos
necesarios para mantener una vigilancia efectiva sobre extensas superficies
de terreno, muchas veces en ubicaciones remotas con acceso limitado a
infraestructura de comunicaciones.

Las cámaras trampa tradicionales, aunque útiles para la investigación
científica, no fueron diseñadas para la vigilancia en tiempo real. Las
imágenes capturadas permanecen almacenadas en tarjetas de memoria que
deben ser recolectadas físicamente, lo que implica visitas frecuentes
al campo y retrasos significativos entre la captura de un evento y su
descubrimiento. Para cuando se detecta una intrusión o un acto de \gls{caza-furtiva},
los responsables ya se encuentran lejos del área.

Es cierto que en la actualidad existen cámaras trampa más modernas que
incorporan conectividad celular o satelital, permitiendo el envío remoto
de imágenes. Sin embargo, estos dispositivos suelen tener un costo
significativamente mayor, lo que limita su adopción masiva especialmente
en países en vías de desarrollo, donde paradójicamente se concentra gran
parte de la biodiversidad mundial. Además, muchas de estas soluciones
comerciales dependen de servicios en la nube propietarios con costos
de suscripción recurrentes.

La motivación de este proyecto surge de la necesidad de transformar el
paradigma del monitoreo pasivo hacia un sistema activo de vigilancia
inteligente, pero de manera accesible y de bajo costo. Un sistema que
no solo capture imágenes, sino que las transmita en \gls{tiempo-real}, las
analice automáticamente mediante algoritmos de \gls{ia}, y genere alertas
inmediatas cuando se detecten eventos de interés, ya sea la presencia
de fauna silvestre para fines de investigación, o la detección de intrusos
para fines de seguridad. Todo esto utilizando componentes de hardware
económicos y software de \gls{codigo-abierto}.

\section{Estructura del documento}

El presente documento se organiza en nueve capítulos que describen de
manera progresiva el desarrollo del sistema propuesto:

\begin{description}
	\item[Capítulo 1 - Introducción:] Presenta el contexto general del
	      proyecto, la motivación y la estructura del documento.

	\item[Capítulo 2 - Antecedentes:] Revisa trabajos relacionados,
	      soluciones comerciales existentes y el estado del arte en sistemas
	      de monitoreo de fauna y detección de intrusos.

	\item[Capítulo 3 - Planteamiento del Problema:] Describe la
	      problemática de las áreas protegidas, las limitaciones de los
	      sistemas tradicionales y la justificación del proyecto.

	\item[Capítulo 4 - Objetivos y Alcance:] Define los objetivos
	      generales y específicos, así como el alcance y las limitaciones
	      del trabajo.

	\item[Capítulo 5 - Marco Teórico:] Presenta los fundamentos teóricos
	      sobre \gls{iot}, redes \gls{mesh}, \gls{ia} aplicada a \gls{vision-computadora},
	      y las tecnologías utilizadas.

	\item[Capítulo 6 - Metodología:] Describe el enfoque metodológico,
	      las etapas de desarrollo, las herramientas empleadas y las métricas
	      de evaluación.

	\item[Capítulo 7 - Diseño e Implementación:] Detalla la arquitectura
	      del sistema, el diseño e implementación de cada componente: nodos
	      de cámara, nodo raíz, red \gls{mesh}, servicio de detección y
	      servidor de aplicación.

	\item[Capítulo 8 - Pruebas y Resultados:] Documenta las pruebas
	      realizadas y analiza los resultados obtenidos en conectividad,
	      detección, rendimiento y consumo energético.

	\item[Capítulo 9 - Conclusiones:] Resume las conclusiones generales,
	      los aportes del trabajo, trabajos futuros y recomendaciones.
\end{description}

% ==============================================================================
% Capítulo 2: Antecedentes
% ==============================================================================
\chapter{Antecedentes}

En los últimos años, el campo de la \gls{ia} aplicada a la \gls{vision-computadora} ha experimentado avances significativos. El desarrollo de
arquitecturas de \glspl{cnn} cada vez más eficientes, junto con la
disponibilidad de grandes conjuntos de datos de entrenamiento, ha permitido
crear modelos capaces de detectar y clasificar objetos en imágenes con
una precisión sin precedentes \cite{schneider2018deep}. Algoritmos como
\gls{yolo} \cite{redmon2016yolo} y sus sucesivas versiones, incluyendo
\gls{yolov5} \cite{jocher2020yolov5}, han revolucionado la \gls{deteccion-objetos},
permitiendo el procesamiento en \gls{tiempo-real} incluso en dispositivos
con recursos limitados.

En el ámbito específico del monitoreo de fauna silvestre, estos avances
han dado lugar a modelos especializados como \gls{speciesnet}, desarrollado
por Google \cite{gadot2024crop}, que combina detección de objetos con
\gls{clasificacion-taxonomica} para identificar especies a partir de imágenes
de \glspl{camara-trampa}. Estos desarrollos han abierto nuevas posibilidades
para automatizar el análisis de las enormes cantidades de imágenes que
generan los sistemas de monitoreo.

Paralelamente, la tecnología de \glspl{camara-trampa} ha evolucionado desde
dispositivos autónomos que almacenan imágenes localmente, hasta sistemas
más sofisticados con conectividad celular o satelital que permiten la
transmisión remota de datos. Este capítulo examina tanto los avances en
\gls{ia} aplicada a la \gls{vision-computadora}, como la evolución de las
soluciones de monitoreo de fauna, incluyendo sistemas comerciales y
proyectos de investigación relacionados.

\section{Trabajos relacionados}

En el ámbito local, Barrero y Schmunck \cite{barrero2023microcamara} desarrollaron
en la Universidad Nacional de Misiones una microcámara de vigilancia orientada
a la protección de fauna salvaje. Este trabajo propuso el diseño de un
dispositivo compacto basado en microcontroladores capaz de capturar imágenes
en áreas naturales. El proyecto sentó las bases para el desarrollo de
soluciones de bajo costo adaptadas a las necesidades específicas de la
región misionera, demostrando la viabilidad de utilizar hardware económico
para aplicaciones de monitoreo ambiental. El presente trabajo extiende
estos conceptos incorporando comunicación en red \gls{mesh}, procesamiento
con \gls{ia} y un sistema de alertas en \gls{tiempo-real}.

En el contexto regional argentino, González et al. \cite{gonzalez2022fauna}
presentaron en el Workshop de Investigadores en Ciencias de la Computación
(WICC 2022) un sistema de \gls{ia} para la multi-clasificación de fauna
en fotografías automáticas utilizadas en investigación científica. Este
trabajo demuestra el creciente interés en la comunidad científica argentina
por aplicar técnicas de \gls{aprendizaje-automatico} al análisis de imágenes
de \glspl{camara-trampa}, estableciendo un precedente importante para
proyectos de monitoreo de fauna en el país.

En el contexto internacional, diversos trabajos han explorado el uso de
\gls{yolov5} para el análisis automatizado de imágenes de \glspl{camara-trampa}.
Abood et al. \cite{abood2023yolov5wildlife} presentaron un enfoque innovador
en la conferencia IEEE ICMNWC 2023, demostrando que los modelos de la familia
\gls{yolo} pueden adaptarse eficazmente para la detección y clasificación
de fauna silvestre. Los autores destacaron las ventajas de \gls{yolov5} en
términos de velocidad de \gls{inferencia} y precisión. De manera similar,
Njathi et al. \cite{njathi2023annotation} propusieron en IEEE AFRICON 2023
un sistema eficiente de anotación de imágenes de cámaras trampa basado en
\gls{yolov5}, enfocándose en reducir el tiempo y esfuerzo requerido para
etiquetar grandes conjuntos de datos. Ambos trabajos evidencian la idoneidad
de los modelos \gls{yolo} para aplicaciones de monitoreo de fauna que
requieren procesamiento eficiente de grandes volúmenes de imágenes.

Un antecedente particularmente relevante para el presente trabajo es el
sistema propuesto por Whytock et al. \cite{whytock2023iridium}, quienes
desarrollaron cámaras trampa con \gls{ia} capaces de enviar alertas en
\gls{tiempo-real} a través de la red satelital Iridium. El estudio, realizado
en Gabón (África Central), demostró la viabilidad de integrar procesamiento
con \gls{ia} directamente en dispositivos de campo para detectar fauna y
enviar notificaciones inmediatas a investigadores y guardaparques. Aunque
su solución utiliza conectividad satelital ---con costos operativos
significativos---, el concepto de alertas en tiempo real basadas en
detección automática constituye un pilar fundamental del sistema propuesto
en este trabajo. La diferencia principal radica en que nuestra solución
emplea redes \gls{mesh} locales y conectividad Wi-Fi/TCP, reduciendo
considerablemente los costos de operación.

Otro proyecto directamente comparable es AiCatcher, desarrollado por
Mallya \cite{mallya2019aicatcher}, que propone una cámara trampa inteligente
capaz de realizar \gls{inferencia} directamente en el dispositivo de campo.
AiCatcher utiliza una Raspberry Pi como unidad de procesamiento para ejecutar
modelos de detección en el borde (\gls{edge-computing}), y emplea módulos \gls{lora}
(Adafruit LoRa Bonnets) configurados en una red \gls{lorawan} para la transmisión
de datos, convirtiendo las señales recibidas en mensajes SMS mediante Twilio.
Si bien este enfoque es innovador, el uso de Raspberry Pi presenta un consumo
energético significativamente mayor, limitando la autonomía del dispositivo
en campo. En contraste, nuestra solución emplea microcontroladores \gls{ESP32}
de bajo consumo para la captura y transmisión, delegando el procesamiento
de \gls{ia} a un servidor remoto. Además, el uso de redes \gls{mesh} en
nuestra propuesta permite una topología de red más flexible y autoorganizada.

\section{Estado del arte}

Vélez et al. \cite{velez2022platforms} realizaron una evaluación exhaustiva
de las plataformas disponibles para el procesamiento de imágenes de
\glspl{camara-trampa} utilizando \gls{ia}. Su estudio, publicado en
\textit{Methods in Ecology and Evolution}, comparó múltiples herramientas
en términos de precisión, facilidad de uso y requisitos computacionales.
Los autores concluyeron que, si bien existen diversas opciones de
\gls{codigo-abierto} y comerciales, la elección de la plataforma adecuada
depende del contexto específico de cada proyecto, incluyendo el volumen
de imágenes, las especies objetivo y los recursos disponibles. Este análisis
proporciona un marco de referencia valioso para la selección de tecnologías
en proyectos de monitoreo de fauna.

Tabak et al. \cite{tabak2019machine} demostraron la aplicabilidad del
\gls{aprendizaje-automatico} para clasificar especies animales en imágenes de
cámaras trampa, alcanzando precisiones superiores al 90\% en la identificación
de especies comunes. Su trabajo destacó la importancia de contar con conjuntos
de datos de entrenamiento representativos de las condiciones locales para
optimizar el rendimiento de los modelos.

Por su parte, Steenweg et al. \cite{steenweg2017scaling} abordaron el desafío
de escalar las redes de \glspl{camara-trampa} para el monitoreo de biodiversidad
a nivel global. Los autores argumentaron que la integración de sensores remotos
en redes coordinadas, combinada con técnicas de análisis automatizado, representa
el futuro del monitoreo de fauna silvestre, permitiendo obtener datos de
biodiversidad a escalas espaciales y temporales sin precedentes.

Entre las plataformas más recientes, Hernández et al. \cite{hernandez2024pytorchwildlife}
presentaron PyTorch-Wildlife, un framework colaborativo de aprendizaje profundo
desarrollado por Microsoft AI for Good. Esta plataforma, similar en objetivos
a \gls{speciesnet} de Google, ofrece modelos preentrenados para la detección
y clasificación de fauna silvestre en imágenes de \glspl{camara-trampa}.
PyTorch-Wildlife se distingue por su enfoque en la facilidad de uso y la
integración con el ecosistema \gls{pytorch}, facilitando tanto el despliegue de
modelos existentes como el entrenamiento de modelos personalizados para
especies específicas. La existencia de múltiples frameworks de \gls{codigo-abierto}
respaldados por grandes empresas tecnológicas evidencia la relevancia del
problema y la madurez de las soluciones disponibles.

Cabe destacar también \gls{megadetector}, desarrollado originalmente por Microsoft
AI for Earth \cite{beery2019megadetector}, que se ha convertido en una
herramienta fundamental en el procesamiento de imágenes de \glspl{camara-trampa}.
A diferencia de los clasificadores de especies, \gls{megadetector} se especializa
en la detección genérica de animales, humanos y vehículos, funcionando como
un primer filtro que reduce drásticamente el volumen de imágenes a analizar.
Esta herramienta ha sido adoptada por más de 60 organizaciones de conservación
a nivel mundial, demostrando reducciones de hasta el 90\% en el tiempo de
procesamiento de datos. Su arquitectura modular permite integrarlo como
etapa previa a clasificadores más específicos como \gls{speciesnet}.

\section{Soluciones comerciales existentes}

En el mercado actual, existen diversas soluciones comerciales diseñadas para
el monitoreo remoto de fauna. Las \glspl{camara-trampa} con conectividad
celular, como las series REVEAL de Tactacam \cite{tactacam2024reveal} y las
líneas Flex de Spypoint \cite{spypoint2024cellular}, son las más extendidas.
Estos dispositivos permiten capturar imágenes de alta resolución y enviarlas
a través de redes LTE a una aplicación móvil propietaria. Algunas de sus
características principales incluyen disparo rápido (menor a 0.5 segundos),
visión nocturna por infrarrojos y, en modelos recientes, la capacidad de
solicitar fotografías o videos bajo demanda.

Sin embargo, estas soluciones presentan limitaciones críticas para su adopción
masiva en proyectos de conservación a gran escala o en regiones remotas. En
primer lugar, dependen enteramente de la infraestructura de red celular; en
áreas de selva densa como la de Misiones, la falta de cobertura inalámbrica
en el interior de las reservas suele ser la norma, invalidando el uso de estos
dispositivos para alertas remotas. En segundo lugar, el costo operativo es
elevado, ya que además de que cada cámara en sí tiene un costo de adquisición
significativo, cada dispositivo requiere un plan de datos independiente, con
suscripciones mensuales que pueden oscilar entre los 5 y 15 dólares por unidad
\cite{tactacam2024reveal, spypoint2024cellular}.

En cuanto a la gestión de datos, plataformas como Wildlife Insights
\cite{wildlifeinsights2024} ofrecen una infraestructura robusta basada en la
nube para el almacenamiento y análisis de imágenes mediante \gls{ia}. Esta
herramienta permite filtrar imágenes vacías automáticamente y realizar la
\gls{clasificacion-taxonomica} de especies, facilitando la colaboración entre
investigadores. No obstante, Wildlife Insights está orientada principalmente al
procesamiento posterior (post-hoc) de los datos recolectados manualmente de las
tarjetas SD, y no está diseñada para la vigilancia y respuesta inmediata ante
eventos de intrusión o \gls{caza-furtiva} en tiempo real.

\section{Análisis comparativo}

A fin de situar las necesidades identificadas frente a las alternativas y
trabajos discutidos anteriormente, se presenta a continuación un análisis
comparativo que resume las principales diferencias técnicas y operativas. En la
tabla \ref{tab:comparativa-sistemas} se contrastan las características de las
categorías de soluciones analizadas: cámaras trampa tradicionales, soluciones
comerciales celulares \cite{tactacam2024reveal, spypoint2024cellular}, el
sistema satelital de Whytock et al. \cite{whytock2023iridium} y el enfoque
basado en \gls{edge-computing} de Mallya (AiCatcher) \cite{mallya2019aicatcher}.

\begin{table}[ht]
	\centering
	\caption{Comparativa de soluciones de monitoreo y trabajos relacionados.}
	\label{tab:comparativa-sistemas}
	\begin{tblr}{
			width = \textwidth,
			colspec = {X[2.2,l] *{4}{X[c]}},
			hlines,
			vlines,
			row{1} = {font=\bfseries},
		}
		Característica               & Tradicional & Celular \cite{tactacam2024reveal} & Satelital \cite{whytock2023iridium} & \gls{lora} \cite{mallya2019aicatcher} \\
		Alertas en \gls{tiempo-real} & No          & Sí                                & Sí                                  & Sí                                    \\
		Infraestructura requerida    & Ninguna     & Operador Celular                  & Red Satelital                       & Puerta de enlace \gls{lora}           \\
		Procesamiento de \gls{ia}    & Post-hoc    & No / Limitado                     & Edge (Hardware Dedicado)            & Edge (Raspberry Pi)                   \\
		Costo de adquisición         & Bajo-Medio  & Medio-Alto                        & Muy Alto                            & Medio-Alto                            \\
		Costo Operativo              & Bajo        & Alto (Plan mensual)               & Muy Alto (Iridium)                  & Bajo (SMS/Twilio)                     \\
		Autonomía energética         & Muy Alta    & Media                             & Media-Baja                          & Baja (Raspberry Pi)                   \\
		Escalabilidad                & Laboriosa   & Por suscripción                   & Costo-prohibitiva                   & Media (\gls{lora})                    \\
		Dependencia de terceros      & No          & Muy Alta                          & Muy Alta                            & Media (Twilio)                        \\
	\end{tblr}
\end{table}

Como se desprende de la comparación, si bien existen soluciones de vanguardia,
el acceso a alertas inmediatas suele estar condicionado por elevados costos
operativos o dependencia de infraestructura de terceros (celular o satelital).
Los trabajos de investigación como AiCatcher \cite{mallya2019aicatcher} y el
sistema de Whytock et al. \cite{whytock2023iridium} demuestran la viabilidad de
la \gls{ia} para el filtrado en tiempo real, pero enfrentan desafíos en cuanto
a consumo energético y costos de transmisión.

En este sentido, se identifica una oportunidad para un sistema que combine la
eficiencia en el consumo de los microcontroladores \gls{ESP32} con la
capacidad de extensión de cobertura de las redes \gls{mesh}, permitiendo un
monitoreo inteligente y de bajo costo operativo adaptado a las condiciones
reales observadas en la \gls{selva-misionera}.

% ==============================================================================
% Capítulo 3: Planteamiento del Problema
% ==============================================================================
\chapter{Planteamiento del Problema}

\section{Contexto regional}

La provincia de Misiones, ubicada en el extremo noreste de Argentina, alberga
uno de los ecosistemas más diversos y amenazados del continente \cite{wwf2024atlantic}.
El marco geográfico de este proyecto se sitúa en el corazón de la \gls{selva-paranaense},
una región que requiere estrategias de conservación urgentes y tecnificadas.

\subsection{La Selva Misionera y el Bosque Atlántico}

La \gls{selva-misionera} representa el remanente continuo más extenso del
\gls{bosque-atlantico} ---también conocido como \gls{mata-atlantica}--- en
el Cono Sur. Originalmente, este bioma cubría aproximadamente 1.3 millones
de kilómetros cuadrados, extendiéndose desde la costa atlántica de Brasil
(92\% de su extensión) hasta el este de Paraguay (6\%) y el noreste de
Argentina (2\%) \cite{ribeiro2009atlantic}.

Sin embargo, debido a siglos de expansión agrícola, ganadera y forestal,
hoy solo sobrevive entre el 12\% y 17\% de su extensión original, lo que
lo convierte en uno de los \gls{hotspot-biodiversidad} más amenazados
del planeta \cite{wwf2024atlantic}. Se estima que el \gls{bosque-atlantico}
ha perdido aproximadamente el 88\% de su cobertura vegetal nativa, siendo
reemplazado por paisajes dominados por agricultura, pasturas y áreas urbanas.

Misiones conserva cerca de 1.1 millones de hectáreas de este bosque através
del \gls{corredor-verde}, un sistema de áreas protegidas interconectadas que
posiciona a la provincia como un refugio crítico para la biodiversidad
regional y global \cite{dibitetti2003yaguarete}.

\subsection{Biodiversidad y especies en peligro}

Esta región es hogar de una concentración excepcional de biodiversidad:
a pesar de ocupar menos del 0.5\% del territorio argentino, la \gls{selva-misionera}
alberga más del 50\% de la biodiversidad del país \cite{dibitetti2003yaguarete}.
Se estima que contiene alrededor de 3\,000 especies de plantas vasculares,
554 especies de aves, 120 de mamíferos, 79 de reptiles y 55 de anfibios.

Entre las especies más emblemáticas se encuentra el yaguareté (\textit{Panthera onca}),
declarado \gls{monumento-natural} provincial en 1988 y nacional en 2001. Según
el último censo binacional realizado en 2024, se estima una población de
aproximadamente 84 individuos en el \gls{corredor-verde} entre Argentina y
Brasil, con un rango estimado entre 64 y 110 ejemplares \cite{vidasilvestre2024censo}.
Esta cifra representa casi la mitad de los menos de 250 yaguaretés adultos
que se estima sobreviven en todo el territorio argentino.

Otras especies de importancia para la conservación incluyen el tapir
(\textit{Tapirus terrestris}), el oso hormiguero gigante (\textit{Myrmecophaga tridactyla}),
la yacutinga (\textit{Aburria jacutinga}), el mono caí (\textit{Sapajus nigritus})
y el águila harpía (\textit{Harpia harpyja}). La presencia de estos grandes
vertebrados es un indicador clave del estado de salud del ecosistema, pero su
monitoreo en densas zonas de selva subtropical es extremadamente complejo.

\subsection{Importancia ecológica de la región}

La importancia de la \gls{selva-misionera} trasciende la mera preservación de
especies; actúa como regulador climático, protector de cuencas hídricas y
proveedor de \glspl{servicios-ecosistemicos} esenciales para la región, incluyendo
la regulación del ciclo hidrológico, el secuestro de carbono y la protección
contra la erosión del suelo.

El marco legal para la protección de estos ecosistemas está dado por la
Ley 26.331 de Presupuestos Mínimos de Protección Ambiental de los Bosques
Nativos \cite{ley26331bosques}, que establece un sistema de ordenamiento
territorial basado en tres categorías de conservación:

\begin{description}
	\item[Categoría I (Rojo):] Sectores de muy alto valor de conservación que
	      no deben transformarse. En Misiones, gran parte del \gls{corredor-verde}
	      se encuentra clasificado en esta categoría.
	\item[Categoría II (Amarillo):] Sectores de mediano valor de conservación
	      donde se permite el aprovechamiento sostenible y la restauración.
	\item[Categoría III (Verde):] Sectores de bajo valor de conservación que
	      pueden transformarse parcialmente.
\end{description}

La provincia de Misiones gestiona actualmente 104 áreas naturales protegidas
que suman aproximadamente 1.1 millones de hectáreas, lo que impone la necesidad
de una vigilancia constante para evitar la degradación de estas áreas protegidas
frente a actividades ilícitas como la \gls{caza-furtiva} y la tala clandestina.

\section{Problemáticas de conservación en la región}

A pesar de los esfuerzos institucionales y del marco legal establecido por la
Ley 26.331 \cite{ley26331bosques}, las áreas protegidas de Misiones enfrentan
amenazas persistentes que comprometen la integridad de sus ecosistemas.

\subsection{Deforestación y fragmentación del hábitat}

La pérdida de cobertura boscosa por actividades agrícolas no autorizadas y la
extracción ilegal de madera noble continúan siendo problemas recurrentes. Un
estudio de la Facultad de Agronomía de la Universidad de Buenos Aires reveló
que entre 1990 y 2020 se perdieron aproximadamente 130\,000 hectáreas de bosque
nativo solo en el \gls{corredor-verde}, lo que representa un 13\% del área
original \cite{fauba2024corredorverde}. El análisis indica que el 77\% de la
deforestación ocurre en parcelas menores a 50 hectáreas, frecuentemente
asociadas a ocupaciones espontáneas para cultivos de subsistencia.

Si bien las políticas de control han mostrado resultados positivos ---con una
reducción del 18\% en la deforestación durante 2025, alcanzando 4\,118 hectáreas
anuales frente al promedio histórico de 5\,000 hectáreas
\cite{ecologiamisiones2025deforestacion}---, la \gls{fragmentacion-habitat}
sigue obligando a las especies de gran tamaño, como el yaguareté, a desplazarse
por áreas no protegidas. Esto aumenta el riesgo de conflictos con humanos,
atropellamientos en rutas, y reduce la viabilidad genética de las poblaciones
aisladas.

\subsection{Caza furtiva y tráfico de fauna}

La \gls{caza-furtiva} representa uno de los mayores desafíos para la
conservación en la región. A pesar de la prohibición total de la caza en la
provincia, la incursión de cazadores en el interior de parques provinciales
y reservas privadas es frecuente \cite{ecologiamisiones2024cazafurtiva}. El
problema presenta dos dimensiones principales: una cultural, llevada a cabo
por residentes locales como actividad de subsistencia, y otra de carácter
económico, impulsada por grupos organizados que buscan especies valiosas
para el \gls{trafico-fauna}.

Los puntos más críticos se concentran en las zonas fronterizas con Brasil,
especialmente en áreas como la \gls{reserva-biosfera} Yabotí y los parques
provinciales Piñalito, Urugua-í y Horacio Foerster. Entre las especies más
afectadas se encuentran el tapir (\textit{Tapirus terrestris}), la paca
(\textit{Cuniculus paca}), corzuelas, y aves como tucanes, guacamayos y loros.
Los cazadores utilizan técnicas de acecho, trampas y cebaderos que no solo
afectan a las especies objetivo, sino que degradan la fauna en su totalidad
y ponen en riesgo la seguridad de los guardaparques durante los operativos
de control.

\subsection{Intrusión en áreas protegidas}

La falta de un control perimetral efectivo en las más de 106 áreas protegidas
de la provincia permite la entrada de personas y vehículos no autorizados para
actividades ilícitas. Entre las más frecuentes se encuentran:

\begin{itemize}
	\item Pesca ilegal en cursos de agua dentro de reservas.
	\item Desmonte encubierto para expansión de cultivos.
	\item Instalación de campamentos de caza con infraestructura permanente.
\end{itemize}

Sin un sistema de \gls{alerta-temprana}, estas intrusiones frecuentemente solo se
descubren a posteriori durante patrullajes de rutina, cuando el daño ambiental
ya ha sido perpetrado y los responsables se encuentran lejos del área.

\subsection{Desafíos de la vigilancia en el terreno}

La vigilancia efectiva de áreas protegidas en la \gls{selva-misionera} enfrenta
obstáculos inherentes a las características del terreno y la extensión de las
superficies a cubrir. Con aproximadamente 780\,000 hectáreas distribuidas en
más de 106 áreas protegidas, cualquier estrategia de monitoreo debe contemplar
las siguientes limitaciones:

\begin{description}
	\item[Extensión y accesibilidad:] Las vastas superficies boscosas presentan
	      terreno accidentado, cursos de agua y vegetación densa que dificultan
	      el desplazamiento y limitan el alcance de las patrullas terrestres.
	\item[Cobertura de comunicaciones:] La ausencia de infraestructura celular
	      en zonas profundas de selva impide la comunicación en \gls{tiempo-real}
	      y la coordinación de respuestas ante eventos detectados.
	\item[Latencia en la detección:] El uso de \glspl{camara-trampa} tradicionales,
	      si bien genera datos valiosos para investigación, almacena las imágenes
	      localmente en tarjetas de memoria que deben ser retiradas físicamente,
	      introduciendo demoras de semanas o meses entre la captura y el análisis.
	\item[Volumen de datos:] Las cámaras convencionales generan grandes cantidades
	      de imágenes, muchas disparadas por movimiento de vegetación o fauna no
	      relevante, requiriendo un esfuerzo manual significativo para su revisión.
\end{description}

Estas limitaciones evidencian la necesidad de sistemas tecnológicos capaces de
transmitir alertas en \gls{tiempo-real}, extender la cobertura de comunicaciones
mediante redes autoorganizadas, y filtrar automáticamente las imágenes relevantes
mediante técnicas de \gls{ia}.

\section{Sistemas de monitoreo actuales}

Actualmente, el monitoreo biológico y de vigilancia en las áreas protegidas de
Misiones emplea una combinación de métodos tradicionales que, si bien han
demostrado ser efectivos para la investigación científica, presentan brechas
operativas significativas cuando se aplican a la seguridad ambiental y la
detección de actividades ilícitas.

\subsection{Cámaras trampa convencionales}

El uso de \glspl{camara-trampa} pasivas constituye el estándar de referencia
para el monitoreo de fauna silvestre a nivel mundial \cite{steenweg2017scaling}.
Estos dispositivos se instalan en puntos estratégicos ---senderos de fauna,
fuentes de agua, zonas de paso--- y capturan imágenes automáticamente mediante
sensores de calor y movimiento (\gls{sensor-pir}).

Las \glspl{camara-trampa} tradicionales presentan las siguientes características
operativas:

\begin{itemize}
	\item \textbf{Autonomía energética:} Funcionan con baterías AA o paneles
	      solares, permitiendo operación autónoma durante meses.
	\item \textbf{Almacenamiento local:} Las imágenes se guardan en tarjetas
	      SD que deben ser retiradas físicamente para su análisis.
	\item \textbf{Activación pasiva:} El sensor \gls{pir} detecta cambios de
	      temperatura asociados al movimiento de animales o personas.
	\item \textbf{Operación silenciosa:} Los modelos con flash infrarrojo
	      (\gls{ir}) permiten capturas nocturnas sin alertar a la fauna.
\end{itemize}

En Misiones, estas cámaras son utilizadas tanto por organismos gubernamentales
como por organizaciones de conservación para el monitoreo del yaguareté,
realizar censos de fauna, y documentar la biodiversidad de las reservas
\cite{vidasilvestre2024censo}.

\subsection{Patrullajes terrestres}

Complementariamente, el Cuerpo de Guardaparques realiza patrullajes periódicos
a pie, en vehículo o a caballo. Estos recorridos permiten detectar indicios
de actividad ilícita (campamentos, trampas, rastros de tala) y establecer
presencia disuasoria en las áreas protegidas.

Sin embargo, la efectividad de los patrullajes está limitada por factores
logísticos: la densidad de la vegetación restringe la visibilidad, los
desplazamientos consumen tiempo considerable, y la cobertura territorial
depende directamente de los recursos humanos disponibles.

\subsection{Brechas tecnológicas identificadas}

El análisis de los sistemas actuales revela brechas críticas que limitan
la capacidad de respuesta ante eventos de interés:

\begin{description}
	\item[Latencia en la información:] Las imágenes capturadas por cámaras
	      tradicionales permanecen almacenadas localmente durante semanas o
	      meses hasta su recolección. Un evento de \gls{caza-furtiva} registrado
	      por una cámara solo será conocido mucho después de ocurrido,
	      impidiendo cualquier acción disuasoria o legal inmediata.
	\item[Clasificación manual:] El alto volumen de imágenes capturadas
	      ---frecuentemente disparadas por movimiento de vegetación, aves, o
	      pequeños mamíferos no relevantes--- demanda cientos de horas-hombre
	      para su revisión y clasificación manual \cite{tabak2019machine}.
	\item[Ausencia de alertas:] Los sistemas actuales no generan notificaciones
	      en \gls{tiempo-real}. La información fluye de manera unidireccional
	      desde el campo hacia los centros de análisis, sin retroalimentación
	      inmediata.
	\item[Conectividad limitada:] Las soluciones comerciales con transmisión
	      celular, aunque existen en el mercado \cite{tactacam2024reveal,
		      spypoint2024cellular}, resultan inviables en las zonas interiores de
	      la selva donde no existe cobertura de red móvil, además de representar
	      costos operativos elevados para despliegues a escala.
\end{description}

Estas brechas fundamentan la necesidad de desarrollar un sistema que combine
la robustez de las cámaras de campo con capacidades de transmisión en red,
procesamiento automático mediante \gls{ia}, y generación de alertas en
\gls{tiempo-real}.

\section{Justificación del proyecto}

El análisis de las problemáticas de conservación y las limitaciones de los
sistemas de monitoreo actuales permite identificar una brecha tecnológica
que este proyecto propone abordar.

\subsection{Urgencia de la problemática}

La \gls{selva-misionera} representa el último remanente continuo del
\gls{bosque-atlantico} en Argentina, albergando más del 50\% de la biodiversidad
del país en menos del 0.5\% de su territorio \cite{dibitetti2003yaguarete}. La
presión sobre este ecosistema es constante: entre 1990 y 2020 se perdieron
130\,000 hectáreas de bosque nativo solo en el \gls{corredor-verde}
\cite{fauba2024corredorverde}, mientras que especies emblemáticas como el
yaguareté mantienen poblaciones críticamente bajas ---aproximadamente 84
individuos según el último censo \cite{vidasilvestre2024censo}.

La \gls{caza-furtiva}, la tala ilegal y la intrusión en áreas protegidas
continúan siendo amenazas activas que requieren respuestas inmediatas. Sin
embargo, los sistemas de monitoreo actuales operan con latencias de semanas
o meses, imposibilitando cualquier acción preventiva o disuasoria.

\subsection{Oportunidad tecnológica}

La convergencia de tres desarrollos tecnológicos recientes crea una oportunidad
única para abordar esta problemática:

\begin{description}
	\item[Microcontroladores de bajo costo:] Plataformas como el \gls{ESP32}
	      ofrecen capacidades de procesamiento, conectividad Wi-Fi y gestión
	      de energía a costos inferiores a los 10 dólares por unidad, permitiendo
	      despliegues a escala con presupuestos limitados.
	\item[Redes mesh autoorganizadas:] Protocolos como \gls{ESP-MESH} permiten
	      extender la conectividad en áreas sin infraestructura celular,
	      creando redes que se adaptan dinámicamente a la topología del terreno
	      y toleran fallos de nodos individuales.
	\item[Inteligencia artificial para visión:] Modelos de \gls{codigo-abierto}
	      como \gls{speciesnet} \cite{gadot2024crop} y \gls{megadetector}
	      \cite{beery2019megadetector} permiten clasificar automáticamente
	      imágenes de \glspl{camara-trampa}, distinguiendo fauna silvestre
	      de personas y vehículos con alta precisión.
\end{description}

\subsection{Requisitos del sistema propuesto}

Dada la crítica situación de biodiversidad en Misiones y las brechas identificadas
en los sistemas actuales, se justifica el desarrollo de una solución tecnológica
que cumpla con los siguientes requisitos:

\begin{enumerate}
	\item \textbf{Bajo costo de implementación:} Permitiendo un despliegue
	      distribuido con presupuesto limitado, utilizando hardware basado en
	      \gls{ESP32} y software de \gls{codigo-abierto}.
	\item \textbf{Conectividad independiente:} Empleando redes \gls{mesh} que
	      no requieran infraestructura celular preexistente, adaptándose a la
	      topología irregular de la selva subtropical.
	\item \textbf{Procesamiento inteligente:} Integrando modelos de \gls{ia}
	      como \gls{speciesnet} para filtrar y clasificar imágenes automáticamente,
	      reduciendo el volumen de datos a revisar manualmente.
	\item \textbf{Alertas en tiempo real:} Generando notificaciones inmediatas
	      ante la detección de eventos críticos, ya sea la presencia de fauna
	      en peligro para fines de investigación, o la detección de intrusos
	      para fines de seguridad.
\end{enumerate}

Este proyecto no solo representa un aporte técnico en el área de redes de
sensores e \gls{ia} aplicada a la conservación, sino que constituye una
herramienta de aplicación directa para fortalecer la vigilancia de las áreas
protegidas de la región, democratizando el acceso a tecnologías de monitoreo
inteligente que tradicionalmente han estado reservadas a instituciones con
mayores recursos.

% ==============================================================================
% Capítulo 4: Objetivos y Alcance
% ==============================================================================
\chapter{Objetivos y Alcance}

\section{Objetivo general}

Demostrar la viabilidad técnica de un sistema de monitoreo de bajo costo para
áreas protegidas, basado en nodos de cámara con conectividad \gls{mesh} y
clasificación automática de imágenes mediante \gls{ia}. El sistema deberá ser
capaz de detectar la presencia de animales, personas y vehículos, así como
realizar una \gls{clasificacion-taxonomica} de la fauna identificada. Todo esto
reduciendo significativamente el tiempo de procesamiento de datos desde días o
semanas ---típico de las \glspl{camara-trampa} tradicionales--- a minutos.

\section{Objetivos específicos}

\begin{enumerate}
	\item \textbf{Diseñar e implementar un nodo de cámara autónomo} basado en
	      microcontroladores \gls{ESP32}, capaz de capturar imágenes mediante
	      activación por sensor \gls{pir} y transmitirlas a través de una red
	      \gls{mesh}.

	\item \textbf{Desarrollar una red mesh autoorganizada} utilizando el
	      protocolo \gls{ESP-MESH}, que permita extender la conectividad en
	      áreas sin cobertura celular mediante el encadenamiento de nodos
	      intermedios.

	\item \textbf{Implementar un servidor de procesamiento} capaz de recibir
	      las imágenes transmitidas por la red, clasificarlas automáticamente
	      mediante modelos de \gls{ia} preentrenados, y generar notificaciones
	      ante la detección de eventos de interés.

	\item \textbf{Integrar un modelo de clasificación de fauna} como
	      \gls{speciesnet} o \gls{megadetector}, adaptado para identificar
	      las principales categorías de interés: fauna silvestre, personas y
	      vehículos.

	\item \textbf{Validar el funcionamiento del sistema} en condiciones
	      controladas, evaluando métricas de rendimiento como latencia de
	      transmisión, consumo energético, precisión de clasificación y
	      estabilidad de la red.
\end{enumerate}

\section{Alcance del proyecto}

El presente proyecto tiene como alcance el desarrollo de un prototipo funcional
que demuestre la viabilidad del concepto propuesto. Se contemplan los siguientes
aspectos:

\subsection{Dentro del alcance}

\begin{itemize}
	\item Diseño y construcción de nodos de cámara basados en módulos
	      \gls{ESP32}-CAM con sensor \gls{pir} comercial.
	\item Implementación de la red \gls{mesh} con capacidad de transmisión de
	      imágenes comprimidas.
	\item Desarrollo del servidor de recepción, almacenamiento y clasificación
	      de imágenes.
	\item Integración de un modelo de \gls{ia} preentrenado para la
	      clasificación automática.
	\item Sistema de notificaciones mediante bot de \gls{telegram-bot}.
	\item Pruebas de funcionamiento en entorno controlado (laboratorio).
	\item Validación a pequeña escala en condiciones de campo reales, bajo
	      circunstancias climáticas favorables, dadas las limitaciones de
	      protección del prototipo.
\end{itemize}

\subsection{Fuera del alcance}

\begin{itemize}
	\item Despliegue en áreas protegidas reales o ambientes de selva densa.
	\item Diseño de carcasas con \gls{grado-proteccion-ip} para uso permanente
	      en exteriores.
	\item Entrenamiento de modelos de \gls{ia} específicos para fauna de la
	      región.
	\item Certificación de equipos para uso comercial o institucional.
	\item Integración con sistemas de gestión de áreas protegidas existentes.
\end{itemize}

\section{Limitaciones}

Es importante explicitar las limitaciones técnicas inherentes al prototipo
desarrollado, tanto para establecer expectativas adecuadas como para orientar
trabajos futuros.

\subsection{Limitaciones de hardware}

\begin{description}
	\item[Autonomía energética:] Los nodos de cámara \gls{ESP32} presentan un
	      consumo energético significativo durante la transmisión Wi-Fi. Si
	      bien se implementan estrategias de ahorro de energía, la autonomía
	      con baterías es limitada comparada con cámaras trampa comerciales
	      optimizadas durante años para este propósito. El prototipo utiliza
	      un módulo \gls{buck-converter} basado en el circuito integrado LM2596,
	      que permite alimentar el sistema con packs de \glspl{18650}
	      en diversas configuraciones (2S, 3S, 4S), proporcionando flexibilidad
	      en el voltaje de entrada y permitiendo mayores capacidades de
	      autonomía.

	\item[Sensor de movimiento:] Se utiliza un sensor \gls{pir} domótico
	      convencional, cuyas características de detección están optimizadas
	      para uso en interiores. Esto implica que el sistema es capaz de
	      detectar confiablemente animales de gran porte (tapires, yaguaretés,
	      ciervos) y personas, pero puede no activarse consistentemente ante
	      fauna de menor tamaño como aves o pequeños mamíferos.

	\item[Operación diurna:] El módulo de cámara utilizado incorpora un lente
	      con filtro \gls{ir}, lo que limita su operación a condiciones de
	      luz diurna. A diferencia de las cámaras trampa comerciales que
	      incluyen iluminación infrarroja para capturas nocturnas, el prototipo
	      desarrollado no cuenta con esta capacidad.

	\item[Resolución de imagen:] Además de las limitaciones propias del sensor
	      OV2640, los protocolos \gls{ESP-MESH} y \gls{ESP-MDF} imponen
	      restricciones en el tamaño máximo de los datos transmitidos por
	      paquete. Esto limita la resolución efectiva de las imágenes que
	      pueden transmitirse a través de la red, requiriendo compresión
	      adicional que afecta la calidad final.
\end{description}

\subsection{Consideraciones sobre el tiempo de respuesta}

Es necesario clarificar el uso del término \gls{tiempo-real} en el contexto de
este proyecto. En sistemas embebidos, ``tiempo real'' típicamente se refiere a
la capacidad de responder a eventos dentro de plazos determinísticos estrictos,
frecuentemente en el orden de milisegundos o microsegundos.

En el contexto de este proyecto, la noción de tiempo real se utiliza en un
sentido operativo diferente: la capacidad de reducir la latencia de
procesamiento de imágenes desde \textbf{días o semanas} a \textbf{minutos}.
Los tiempos prolongados característicos de las \glspl{camara-trampa} tradicionales
se deben a la necesidad de desplazarse físicamente hasta cada dispositivo para
recolectar las tarjetas de memoria, y posteriormente procesar las imágenes de
forma manual o semiautomática. Este cambio de escala temporal, aunque no
constituye tiempo real en el sentido determinístico, representa una mejora
de varios órdenes de magnitud que habilita respuestas operativas antes imposibles.

\subsection{Limitaciones de alcance}

\begin{description}
	\item[Rango de comunicación:] El alcance de cada nodo \gls{mesh} depende
	      de las condiciones del terreno y la vegetación. En zonas de selva
	      densa, puede ser necesario un mayor número de nodos intermedios para
	      cubrir distancias equivalentes a las alcanzables en campo abierto.

	\item[Ancho de banda:] La transmisión de imágenes a través de la red
	      \gls{mesh} consume ancho de banda significativo. Capturas simultáneas
	      en múltiples nodos pueden generar congestión y aumentar la latencia.

	\item[Clasificación de especies:] Los modelos de \gls{ia} utilizados están
	      entrenados con datasets globales que pueden no incluir todas las
	      especies presentes en la \gls{selva-misionera}, afectando la precisión
	      de clasificación taxonómica a nivel de especie.
\end{description}

% ==============================================================================
% Capítulo 5: Marco Teórico
% ==============================================================================
\chapter{Marco Teórico}

\section{Internet de las Cosas (IoT)}

El \gls{iot} representa un paradigma de conectividad donde objetos físicos
---equipados con sensores, capacidad de procesamiento y conectividad de red---
intercambian datos con otros dispositivos y sistemas a través de internet o
redes locales. Esta tecnología ha experimentado un crecimiento exponencial en
las últimas décadas, habilitando aplicaciones que van desde la automatización
del hogar hasta el monitoreo ambiental a gran escala \cite{steenweg2017scaling}.

En el contexto de la conservación ambiental, el \gls{iot} permite la creación
de redes de monitoreo autónomas capaces de operar en ubicaciones remotas con
mínima intervención humana. Los sistemas de \glspl{camara-trampa} inteligentes
representan una aplicación específica de este paradigma, donde la combinación
de sensores, procesamiento embebido y conectividad inalámbrica extiende las
capacidades tradicionales de monitoreo de fauna \cite{whytock2023iridium}.

\subsection{Arquitecturas IoT}

Una arquitectura típica de \gls{iot} se compone de tres capas fundamentales:

\begin{description}
	\item[Capa de Percepción:] Formada por los sensores y actuadores que
	      interactúan directamente con el entorno físico. En este proyecto,
	      incluye los sensores \gls{pir} y los módulos de cámara.
	\item[Capa de Red:] Encargada de la transmisión de datos desde los nodos
	      sensores hacia los sistemas de procesamiento. Aquí se implementa
	      la red \gls{ESP-MESH} que permite la comunicación entre nodos.
	\item[Capa de Aplicación:] Donde los datos son procesados, almacenados y
	      presentados al usuario final. Corresponde al servidor \gls{django}
	      con el modelo de \gls{ia} y el sistema de notificaciones.
\end{description}

El sistema desarrollado en esta tesis abarca estas tres capas, utilizando
nodos \gls{ESP32} en la percepción, \gls{ESP-MESH} en la red y un servidor
\gls{django} con \gls{speciesnet} en la aplicación.

\subsection{Protocolos de comunicación inalámbrica}

La elección del protocolo de comunicación es crítica en entornos rurales o
silvestres donde la infraestructura de red tradicional es inexistente. Cada
tecnología presenta compromisos entre alcance, consumo energético y ancho
de banda:

\begin{description}
	\item[Bluetooth Low Energy (BLE):] Ideal para corto alcance (hasta 100m)
	      y muy bajo consumo, pero con ancho de banda insuficiente para
	      transmisión de imágenes.
	\item[ZigBee:] Diseñado para redes de sensores con bajo consumo, pero
	      limitado en velocidad de transferencia y complejidad de implementación.
	\item[LoRa/LoRaWAN:] Excelente para muy largo alcance (varios kilómetros)
	      con bajo consumo, pero el ancho de banda extremadamente limitado
	      (decenas de bytes por segundo) lo hace inadecuado para transmisión
	      de imágenes \cite{whytock2023iridium}.
	\item[Wi-Fi (802.11):] Ofrece alto ancho de banda suficiente para imágenes,
	      pero típicamente requiere infraestructura centralizada y tiene mayor
	      consumo energético.
\end{description}

Las redes \gls{mesh} basadas en Wi-Fi, como \gls{ESP-MESH}, ofrecen un equilibrio
adecuado: permiten la transmisión de imágenes gracias al ancho de banda del
protocolo 802.11, mientras extienden la cobertura sin depender de una única
estación base o infraestructura celular preexistente.

\section{Redes Mesh}

Una red de malla o \gls{mesh} es una topología en la que los nodos se conectan
entre sí de forma dinámica, cooperando para propagar los datos a través de la
red. Esta arquitectura es especialmente robusta frente a fallos de nodos
individuales, ya que la red puede reconfigurarse automáticamente para encontrar
rutas alternativas \cite{espmesh2023}.

\subsection{Topologías de red}

Las topologías de red determinan cómo se organizan y comunican los dispositivos:

\begin{description}
	\item[Topología en estrella:] Común en redes Wi-Fi domésticas, donde todos
	      los dispositivos dependen de un único Punto de Acceso central. Si el
	      AP falla, toda la red queda inoperativa.
	\item[Topología en árbol:] Estructura jerárquica donde existe un
	      \gls{nodo-raiz} que actúa como puerta de enlace hacia redes externas,
	      nodos intermedios que extienden la cobertura, y nodos hoja que
	      únicamente transmiten sus propios datos.
	\item[Topología mesh pura:] Cada nodo puede comunicarse con múltiples
	      vecinos, creando redundancia en las rutas de comunicación.
\end{description}

\gls{ESP-MESH} implementa una topología de árbol con capacidades mesh: cada
\gls{nodo} puede actuar simultáneamente como estación (conectada a un padre)
y como Punto de Acceso (para nodos hijos), utilizando el modo \gls{AP-STA}.
Esto facilita el despliegue en terrenos difíciles o boscosos, donde los
obstáculos físicos limitan la línea de vista directa.

\subsection{ESP-MESH: características técnicas}

\gls{ESP-MESH} es el protocolo desarrollado por Espressif basado en el estándar
IEEE 802.11, que permite conectar cientos de dispositivos \gls{ESP32} en una
sola red \cite{espmesh2023}. Sus principales características incluyen:

\begin{description}
	\item[Autoorganización:] Los nodos seleccionan automáticamente su padre
	      óptimo basándose en la intensidad de señal (\gls{rssi}) y la carga de la red.
	\item[\Gls{autocuracion}:] Si un nodo intermedio falla o pierde conectividad,
	      sus nodos descendientes buscan y se conectan automáticamente a un
	      nuevo padre, sin intervención manual.
	\item[Profundidad configurable:] La red puede extenderse hasta una
	      profundidad máxima definida por el usuario (típicamente 6-10 niveles).
	\item[Transmisión de datos:] Soporta comunicación unicast (a un nodo
	      específico), multicast (a un grupo) y broadcast (a todos los nodos).
\end{description}

\subsection{Componente Mwifi del ESP-MDF}

\gls{mwifi} es un componente del \gls{ESP-MDF} que proporciona una capa de
abstracción sobre \gls{ESP-MESH}, simplificando el desarrollo de aplicaciones.
Sus principales aportes incluyen:

\begin{itemize}
	\item APIs de alto nivel para envío y recepción de datos fragmentados
	\item Gestión automática de la fragmentación de paquetes grandes (como
	      imágenes) que exceden el tamaño máximo de trama Wi-Fi
	\item Soporte para transmisión \gls{tcp} y UDP sobre la red mesh
	\item Eventos de \gls{callback} para monitorear el estado de la topología
	\item Herramientas de depuración integradas
\end{itemize}

La capacidad de fragmentar y reensamblar datos es crítica para este proyecto,
ya que las imágenes capturadas por los nodos exceden significativamente el
tamaño máximo de paquete soportado por el protocolo mesh.

\section{Inteligencia Artificial aplicada a visión por computadora}

La \gls{vision-computadora} busca emular la capacidad humana de interpretar
imágenes digitales. Los avances recientes en este campo, impulsados por el
\gls{aprendizaje-automatico} y específicamente por el aprendizaje profundo
(\textit{deep learning}), han revolucionado el procesamiento automático de
imágenes de \glspl{camara-trampa} \cite{norouzzadeh2018cameratrap}.

\subsection{Redes neuronales convolucionales (CNN)}

Las \glspl{cnn} son arquitecturas de redes neuronales especializadas en
procesar datos con estructura de cuadrícula, como las imágenes
\cite{goodfellow2016deep}. Funcionan mediante la aplicación secuencial de
filtros convolucionales que extraen características en niveles de abstracción
creciente: las primeras capas detectan bordes y texturas básicas, mientras
que las capas profundas reconocen patrones complejos como formas de animales
o rostros humanos.

Esta capacidad de extracción automática de características ---que elimina la
necesidad de diseño manual de descriptores--- ha convertido a las \glspl{cnn}
en la herramienta fundamental para la clasificación de fauna y la detección
de intrusos en imágenes de \glspl{camara-trampa} \cite{tabak2019machine}.

\subsection{Detección de objetos con YOLO}

\gls{yolo} (\textit{You Only Look Once}) es uno de los algoritmos de
\gls{deteccion-objetos} más utilizados debido a su velocidad y precisión
\cite{redmon2016yolo}. A diferencia de métodos tradicionales que analizan una
imagen en múltiples pasadas, YOLO trata la detección como un problema de
regresión único, prediciendo las \glspl{bounding-box} y las probabilidades
de clase simultáneamente para toda la imagen en una sola evaluación.

La arquitectura \gls{yolov5} \cite{jocher2020yolov5}, implementada sobre
\gls{pytorch}, ofrece un excelente equilibrio entre rendimiento computacional
y exactitud. Sus variantes (desde YOLOv5n para dispositivos embebidos hasta
YOLOv5x para máxima precisión) permiten adaptar el modelo a los recursos
disponibles.

\subsection{MegaDetector}

\gls{megadetector} es un modelo de detección desarrollado por Microsoft AI
for Earth \cite{beery2019megadetector}, específicamente diseñado para imágenes
de \glspl{camara-trampa}. A diferencia de clasificadores que intentan
identificar especies directamente, MegaDetector se enfoca en una tarea más
simple: detectar la presencia y ubicación de tres categorías principales:

\begin{itemize}
	\item Animales (sin distinción de especie)
	\item Personas
	\item Vehículos
\end{itemize}

Esta aproximación en dos etapas ---primero detectar, luego clasificar--- ha
demostrado ser más robusta y generalizable que intentar resolver ambos
problemas simultáneamente \cite{velez2022platforms}.

\subsection{SpeciesNet de Google}

\gls{speciesnet} es un sistema de \gls{ia} de \gls{codigo-abierto} desarrollado
por Google \cite{gadot2024crop}, diseñado específicamente para el análisis de
imágenes de \glspl{camara-trampa}. Combina las capacidades de detección con
modelos de \gls{clasificacion-taxonomica} entrenados con millones de imágenes
de cientos de especies a nivel global.

El pipeline de SpeciesNet opera en dos fases:
\begin{enumerate}
	\item \textbf{Detección:} Identifica regiones de interés en la imagen
	      (animales, personas, vehículos) similar a MegaDetector.
	\item \textbf{Clasificación:} Para las regiones identificadas como animales,
	      aplica un clasificador taxonómico que predice familia, género y
	      especie.
\end{enumerate}

En este proyecto, SpeciesNet actúa como el núcleo de procesamiento del
servidor, validando si las imágenes capturadas por los nodos contienen
fauna de interés, personas o vehículos, y generando las alertas correspondientes.

\section{Tecnologías de desarrollo}

Para la implementación del sistema se han seleccionado herramientas que
garantizan modularidad, facilidad de mantenimiento e interoperabilidad,
priorizando tecnologías de \gls{codigo-abierto} cuando sea posible.

\subsection{Microcontroladores ESP32}

El \gls{ESP32} es un \gls{soc} de bajo costo diseñado por Espressif Systems,
que integra conectividad Wi-Fi (802.11 b/g/n) y Bluetooth en un único chip
\cite{espressif2023esp32}. Sus principales características técnicas incluyen:

\begin{itemize}
	\item Procesador Xtensa LX6 de doble núcleo a 240 MHz
	\item 520 KB de SRAM interna
	\item Soporte para memoria flash externa (hasta 16 MB)
	\item Múltiples modos de bajo consumo (\gls{deep-sleep} $<$ 10 µA)
	\item Rico conjunto de periféricos: SPI, I2C, UART, ADC, DAC, PWM
\end{itemize}

La variante ESP32-CAM incorpora un módulo de cámara OV2640 y ranura para
tarjeta microSD, proporcionando una plataforma compacta para aplicaciones
de captura de imagen con conectividad inalámbrica.

\subsection{ESP-IDF y ESP-MDF}

El \gls{ESP-IDF} (IoT Development Framework) es el entorno de desarrollo
oficial para el ESP32 \cite{espmesh2023}, basado en \gls{freertos}. Proporciona
control preciso sobre el hardware, gestión de energía y acceso a todas las
funcionalidades del chip.

Sobre este entorno, el \gls{ESP-MDF} (Mesh Development Framework) agrega
herramientas específicas para redes mesh:

\begin{itemize}
	\item Componente \gls{mwifi} para comunicación mesh de alto nivel
	\item Gestión automática de topología y enrutamiento
	\item Capacidades de actualización remota de \gls{firmware} \gls{ota}
	\item Herramientas de depuración y monitoreo de red
\end{itemize}

\subsection{Contenedorización con Docker}

\gls{docker} es una plataforma de contenedorización que permite empaquetar
aplicaciones junto con todas sus dependencias en unidades estandarizadas
llamadas contenedores. El uso de \gls{docker} y \gls{docker-compose} en este
proyecto facilita el despliegue del servidor de procesamiento en cualquier
máquina, asegurando que el entorno de ejecución sea idéntico al de desarrollo.

Los componentes del servidor se organizan en contenedores separados:
\begin{itemize}
	\item Contenedor de \gls{speciesnet} para inferencia de IA
	\item Contenedor de base de datos \gls{postgresql}
	\item Contenedor del backend \gls{django}
\end{itemize}

\subsection{Framework Django}

\gls{django} es un framework web de alto nivel escrito en Python que fomenta
el desarrollo rápido y un diseño limpio. Se utiliza para construir el servidor
central que recibe las imágenes de la red \gls{mesh}, interactúa con el sistema
de \gls{ia} y gestiona el almacenamiento persistente.

Su arquitectura MVT (Modelo-Vista-Plantilla) permite una separación clara entre
la lógica de datos, el procesamiento de solicitudes y la presentación de
resultados al usuario.

\section{Sensores y actuadores}

Los componentes físicos periféricos permiten la interacción del nodo con el
entorno, detectando eventos y capturando información visual. La selección de
estos componentes determina las capacidades y limitaciones del sistema.

\subsection{Sensores de movimiento PIR}

El \gls{sensor-pir} detecta movimiento mediante la medición de cambios en los
niveles de radiación infrarroja emitida por objetos en su campo de visión. El
sensor contiene un elemento piroeléctrico dividido en dos zonas: cuando un objeto
emisor de calor (como un humano o animal) cruza de una zona a otra, se genera
una diferencia de voltaje que activa la detección.

Los sensores PIR domóticos utilizados en este proyecto tienen un rango de
detección optimizado para objetos del tamaño de humanos, lo que limita la
capacidad de detectar fauna de pequeño porte pero es adecuado para animales
medianos y grandes como tapires, yaguaretés o ciervos.

\subsection{Módulos de cámara OV2640}

El OV2640 es un sensor de imagen CMOS de 2 megapíxeles fabricado por OmniVision,
ampliamente utilizado en aplicaciones embebidas por su bajo costo y consumo
moderado. Sus especificaciones técnicas principales incluyen:

\begin{itemize}
	\item Resolución máxima: 1600 × 1200 píxeles (UXGA)
	\item Formatos de salida: \gls{jpeg}, RGB565, YUV422
	\item Interfaz: SCCB (compatible con I2C) para control, paralelo para datos
	\item Compresión JPEG integrada en hardware
	\item Consumo típico: 125 mW en operación activa
\end{itemize}

El módulo está integrado en placas de desarrollo como la ESP32-CAM, que incluye
slot para tarjeta microSD, LED flash, y antena Wi-Fi externa opcional. La
compresión JPEG en hardware es particularmente útil para reducir el tamaño de
las imágenes antes de su transmisión por la red \gls{mesh}.

El lente incluido en los módulos comerciales típicamente incorpora un filtro
\gls{ir}, lo que limita la operación a condiciones de luz diurna.

\section{Diseño y fabricación digital}

La protección física del hardware es fundamental para la operación del sistema
en entornos exteriores, donde los componentes electrónicos están expuestos a
condiciones ambientales adversas.

\subsection{Modelado 3D}

El diseño de la \gls{carcasa} protectora se realiza mediante herramientas de
\gls{cad}, permitiendo crear estructuras precisas adaptadas a los componentes
específicos del nodo. Los requisitos principales del diseño incluyen:

\begin{itemize}
	\item Protección contra humedad y polvo
	\item Aperturas dimensionadas para la lente de cámara y sensor PIR
	\item Espacio para el módulo \gls{buck-converter} y conexión a pack de
	      \glspl{18650} externo
	\item Puntos de montaje para fijación en árboles o postes
	\item Acceso a la ranura de tarjeta SD sin desmontar el dispositivo
\end{itemize}

\subsection{Fabricación aditiva}

La \gls{impresion-3d} mediante tecnología \gls{fdm} es la técnica utilizada para
materializar los diseños. Esta tecnología permite iterar rápidamente sobre
prototipos y fabricar piezas personalizadas sin inversión en moldes.

La selección del material de impresión es crítica para la durabilidad. Para los
prototipos de validación de este proyecto se utiliza \gls{pla}, dado que las
pruebas de campo se realizarán bajo condiciones climáticas favorables y
no se planea exposición prolongada a la intemperie. Sin embargo, el mismo modelo
3D puede ser fabricado en materiales más resistentes como \gls{petg} o \gls{asa} en
fases posteriores de despliegue que requieran operación permanente en exteriores.

% ==============================================================================
% Capítulo 6: Metodología
% ==============================================================================
\chapter{Metodología}

\section{Enfoque metodológico}

El desarrollo de este proyecto siguió un enfoque \textbf{iterativo e incremental},
donde cada componente del sistema fue desarrollado, probado y refinado antes de
avanzar al siguiente. Esta aproximación permitió identificar y corregir problemas
tempranamente, reduciendo el riesgo de fallas críticas en etapas avanzadas.

Se adoptó la metodología ágil \gls{kanban} para la gestión del proyecto,
caracterizada por:

\begin{itemize}
	\item Visualización del flujo de trabajo mediante un tablero con columnas
	      (Por hacer, En progreso, En revisión, Completado).
	\item Limitación del trabajo en progreso para mantener el enfoque en tareas
	      específicas.
	\item Entrega continua de funcionalidades incrementales.
	\item Flexibilidad para repriorizar tareas según las necesidades emergentes.
\end{itemize}

Esta metodología resultó particularmente adecuada para un proyecto que combina
hardware y software, donde los ciclos de iteración pueden variar significativamente
entre componentes: el desarrollo de \gls{firmware} requiere ciclos más largos de
compilación y flasheo, mientras que el desarrollo del servidor permite iteraciones
más rápidas.

\section{Etapas del desarrollo}

El proyecto se estructuró en las siguientes etapas principales, representadas
en el diagrama de Gantt de la Figura \ref{fig:gantt-desarrollo}:

\begin{enumerate}
	\item \textbf{Investigación y diseño:} Revisión del estado del arte, definición
	      de requisitos y diseño de la arquitectura general del sistema.
	\item \textbf{Desarrollo del firmware:} Implementación del código para los
	      nodos \gls{ESP32}, incluyendo captura de imágenes, integración del
	      sensor \gls{pir} y comunicación \gls{mesh}.
	\item \textbf{Desarrollo del servidor:} Implementación del backend \gls{django},
	      integración con \gls{speciesnet} y sistema de notificaciones.
	\item \textbf{Diseño y fabricación de hardware:} Modelado 3D de la \gls{carcasa}
	      e impresión de prototipos.
	\item \textbf{Integración:} Conexión de todos los componentes del sistema y
	      verificación del flujo completo de datos.
	\item \textbf{Pruebas y validación:} Evaluación del sistema en condiciones
	      controladas y de campo.
\end{enumerate}

% Placeholder para el diagrama de Gantt
% TODO: Agregar archivo gantt.puml y generar imagen
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=\textwidth]{figures/gantt-desarrollo.png}
	\fbox{\parbox{0.9\textwidth}{\centering\vspace{2cm}
			[Diagrama de Gantt - Por agregar]
			\vspace{2cm}}}
	\caption{Cronograma de desarrollo del proyecto.}
	\label{fig:gantt-desarrollo}
\end{figure}

\section{Herramientas y tecnologías utilizadas}

\subsection{Entorno de desarrollo}

\begin{description}
	\item[Editor de código:] Visual Studio Code con extensiones para desarrollo
	      en C/C++ (ESP-IDF), Python y Docker.
	\item[Framework de firmware:] \gls{ESP-IDF} y \gls{ESP-MDF} para el desarrollo
	      del código de los nodos \gls{ESP32}.
	\item[Framework web:] \gls{django} para el servidor de aplicación.
	\item[Bot de notificaciones:] Librería \texttt{python-telegram-bot} para
	      la implementación del sistema de alertas mediante Telegram.
	\item[Contenedorización:] \gls{docker} y \gls{docker-compose} para el
	      despliegue de servicios.
\end{description}

\subsection{Diseño y fabricación 3D}

\begin{description}
	\item[Software de modelado:] Autodesk Fusion 360 con licencia educativa para
	      el diseño de la \gls{carcasa} del nodo.
	\item[Software de laminado:] PrusaSlicer para la preparación de modelos 3D
	      y generación de \gls{gcode} para la impresora.
	\item[Impresora 3D:] Creality Ender 3 con cama caliente, utilizando filamento
	      \gls{pla} para los prototipos de validación.
\end{description}

\subsection{Control de versiones y despliegue}

El código fuente del proyecto fue organizado en cuatro repositorios \gls{git} alojados
en GitHub:
\begin{enumerate}
	\item Repositorio del \gls{firmware} para nodos de cámara:\\
	      \url{https://github.com/fabcontigiani/mesh-node-capstone-project}
	\item Repositorio del \gls{firmware} para nodo raíz:\\
	      \url{https://github.com/fabcontigiani/root-node-capstone-project}
	\item Repositorio del servidor de aplicación:\\
	      \url{https://github.com/fabcontigiani/server-capstone-project}
	\item Repositorio del servidor de inferencia y anotación de imágenes:\\
	      \url{https://github.com/fabcontigiani/wildlife-detection-capstone-project}
\end{enumerate}

\subsection{Despliegue continuo}

Se implementó una estrategia de \gls{despliegue-continuo} mediante \gls{github-actions}
para automatizar las siguientes tareas:

\begin{itemize}
	\item Construcción automática de imágenes \gls{docker} al realizar cambios
	      en las ramas principales de los repositorios.
	\item Publicación de las imágenes en el registro de contenedores de GitHub
	      (GitHub Container Registry).
\end{itemize}

Esta automatización garantizó que las versiones desplegadas del servidor
siempre correspondieran al código más reciente validado, reduciendo errores
humanos en el proceso de despliegue.

\section{Métricas de evaluación}

Para validar el cumplimiento de los objetivos del proyecto, se definieron las
siguientes métricas de evaluación:

\subsection{Métricas de rendimiento de red}

\begin{description}
	\item[Latencia de transmisión:] Tiempo transcurrido desde la captura de una
	      imagen en el nodo hasta su recepción completa en el servidor. Se mide
	      en segundos y representa la capacidad del sistema para proporcionar
	      información en tiempos operativamente útiles.
	\item[Distancia máxima entre nodos:] Distancia física máxima a la cual dos
	      nodos pueden mantener una conexión \gls{mesh} funcional, medida en
	      metros. Esta métrica determina la densidad de nodos necesaria para
	      cubrir un área determinada.
	\item[Estabilidad de la red:] Tasa de pérdida de paquetes y frecuencia de
	      reconexiones durante operación prolongada. Una red estable debe
	      mantener tasas de pérdida inferiores al 5\%.
\end{description}

\subsection{Métricas de clasificación}

\begin{description}
	\item[Precisión de detección:] Proporción de imágenes correctamente
	      clasificadas como conteniendo animales, personas, vehículos o
	      imágenes vacías.
	\item[Precisión de clasificación taxonómica:] Para las imágenes con animales,
	      proporción de especies correctamente identificadas a nivel de familia
	      o género.
\end{description}

\subsection{Métricas de consumo energético}

\begin{description}
	\item[Consumo promedio del nodo:] Consumo eléctrico promedio del nodo de
	      cámara durante un ciclo típico de operación (espera + captura +
	      transmisión), medido en miliamperios (mA).
	\item[Autonomía estimada:] Tiempo de operación estimado con una batería de
	      capacidad conocida, calculado a partir del consumo promedio.
\end{description}

\section{Estrategia de pruebas}

\subsection{Pruebas incrementales de firmware}

Durante el desarrollo del \gls{firmware}, cada módulo fue probado de forma
aislada antes de su integración:

\begin{itemize}
	\item Pruebas de captura de imagen con el módulo OV2640
	\item Pruebas de detección del sensor \gls{pir}
	\item Pruebas de conexión y transmisión \gls{mesh} entre nodos
	\item Pruebas de consumo energético
\end{itemize}

\subsection{Pruebas de integración}

Una vez validados los componentes individuales, se realizaron pruebas de
integración verificando:

\begin{itemize}
	\item Transmisión de imágenes desde nodos de cámara hasta el servidor
	\item Procesamiento de imágenes por el modelo de \gls{ia}
	\item Generación de notificaciones mediante el bot de \gls{telegram-bot}
\end{itemize}

\subsection{Pruebas de sistema}

Las pruebas del sistema completo se realizaron en dos fases:

\begin{description}
	\item[Fase 1 - Pruebas de laboratorio:] Validación del funcionamiento del
	      sistema en condiciones controladas de interior, verificando la
	      correcta integración de todos los componentes y midiendo las métricas
	      de rendimiento base.
	\item[Fase 2 - Pruebas de campo:] Instalación del sistema en un entorno
	      exterior bajo condiciones climáticas favorables. Durante varias horas
	      se monitoreó el funcionamiento del sistema, registrando las métricas
	      de latencia, estabilidad de red, consumo energético y precisión de
	      clasificación en condiciones realistas.
\end{description}

% ==============================================================================
% Capítulo 7: Diseño e Implementación del Sistema
% ==============================================================================
\chapter{Diseño e Implementación del Sistema}

\section{Arquitectura general}

El sistema propuesto se compone de tres capas principales que trabajan de forma
coordinada para lograr la detección y notificación de eventos en tiempo
operativo:

\begin{enumerate}
	\item \textbf{Capa de percepción:} Formada por los nodos de cámara
	      (mesh-node) equipados con sensor \gls{pir} y módulo de cámara,
	      responsables de detectar movimiento y capturar imágenes.
	\item \textbf{Capa de red:} Constituida por la red \gls{ESP-MESH} que
	      permite la comunicación entre nodos de cámara y el nodo raíz,
	      extendiendo la cobertura sin infraestructura adicional.
	\item \textbf{Capa de aplicación:} Compuesta por el servidor de
	      procesamiento que recibe las imágenes, realiza la inferencia
	      mediante \gls{ia} y notifica al usuario a través de \gls{telegram-bot}.
\end{enumerate}

El flujo de datos del sistema opera de la siguiente manera:

\begin{enumerate}
	\item El sensor \gls{pir} detecta movimiento y genera una interrupción
	      en el microcontrolador.
	\item El nodo de cámara captura una imagen en formato \gls{jpeg}.
	\item La imagen se fragmenta y transmite a través de la red \gls{mesh}
	      hasta el nodo raíz.
	\item El nodo raíz envía la imagen al servidor mediante una petición
	      HTTP POST.
	\item El servidor procesa la imagen con \gls{speciesnet} (que incluye
	      \gls{megadetector} y modelos de clasificación taxonómica).
	\item Si se detecta un objeto de interés con alto grado de confianza,
	      el bot de Telegram notifica al usuario enviando la imagen original,
	      la imagen anotada con las detecciones, y la lista de clasificaciones.
	\item Las imágenes y metadatos se almacenan en la base de datos.
\end{enumerate}

\section{Nodo de cámara (mesh-node)}

\subsection{Selección de componentes}

El nodo de cámara se construye alrededor de los siguientes componentes
principales:

\begin{description}
	\item[Microcontrolador:] Módulo ESP32-CAM de AI-Thinker, que integra un
	      \gls{ESP32} con cámara OV2640 y ranura para tarjeta microSD en una
	      placa compacta.
	\item[Sensor de movimiento:] Módulo HC-SR501, un sensor \gls{pir} de bajo
	      costo con sensibilidad y tiempo de retardo ajustables mediante
	      potenciómetros.
	\item[Regulador de voltaje:] Módulo \gls{buck-converter} basado en el
	      circuito integrado LM2596, que acepta voltajes de entrada entre
	      4.5V y 40V, permitiendo alimentación desde packs de baterías
	      \glspl{18650} en configuración 2S (7.4V nominal).
\end{description}

\subsection{Diseño del firmware}

El firmware del nodo de cámara se desarrolló utilizando \gls{ESP-IDF} y
\gls{ESP-MDF}, implementando las siguientes funcionalidades:

\begin{itemize}
	\item Inicialización y configuración de la cámara OV2640
	\item Configuración del pin GPIO como interrupción externa para el sensor PIR
	\item Conexión a la red \gls{ESP-MESH} como nodo hijo
	\item Captura y compresión de imágenes en formato \gls{jpeg}
	\item Almacenamiento local de imágenes en tarjeta microSD como respaldo
	\item Transmisión de imágenes mediante \gls{mwifi}
	\item Gestión del modo \gls{power-save} para reducir consumo energético
\end{itemize}

\subsection{Captura de imágenes}

La captura de imágenes se realiza con los siguientes parámetros:

\begin{description}
	\item[Resolución:] 640 $\times$ 480 píxeles (VGA)
	\item[Formato:] \gls{jpeg} con compresión alta
	\item[Tamaño típico:] Inferior a 8 KB por imagen, ajustando el nivel
	      de compresión para cumplir con el límite de \gls{ESP-MDF}
\end{description}

El tamaño de imagen se mantiene por debajo del límite de 8 KB impuesto
por \gls{ESP-MDF} para el tamaño máximo de paquete de aplicación. Este
límite determina el nivel de compresión \gls{jpeg} necesario, priorizando
la transmisión confiable sobre la calidad de imagen.

\subsection{Integración del sensor PIR}

El sensor HC-SR501 se conecta a un pin GPIO del ESP32-CAM configurado
como fuente de interrupción externa. Cuando el sensor detecta movimiento
(cambio en la radiación infrarroja), genera una señal HIGH que dispara
la rutina de captura de imagen.

El sensor permite ajustar:
\begin{itemize}
	\item \textbf{Sensibilidad:} Distancia de detección (3-7 metros)
	\item \textbf{Tiempo de retardo:} Duración de la señal HIGH (5s-300s)
\end{itemize}

\subsection{Compresión y transmisión}

La transmisión de imágenes a través de la red \gls{mesh} utiliza el
componente \gls{mwifi} del \gls{ESP-MDF}. Dado que las imágenes se
mantienen por debajo del límite de 8 KB, se transmiten como un único
paquete de aplicación, simplificando el manejo de datos.

El componente \gls{mwifi} proporciona:

\begin{itemize}
	\item Fragmentación automática a nivel de capa de enlace
	\item Ventana deslizante para control de flujo
	\item Retransmisión automática de paquetes perdidos
	\item Reensamblado de fragmentos en el destino
\end{itemize}

\subsection{Carcasa para impresión 3D}

El diseño de la carcasa se basó en un modelo público bajo licencia
Creative Commons 4.0 International, disponible en
Printables\footnote{\url{www.printables.com/model/520378-case-for-esp32_cam-trail-camera-pir-sensor-18650-b}},
el cual fue modificado utilizando Autodesk Fusion 360 para adaptarlo a los
requerimientos específicos del proyecto. La carcasa fue impresa en \gls{pla}
y contempla:

\begin{itemize}
	\item Apertura frontal para la lente de la cámara
	\item Apertura superior para el domo del sensor PIR
	\item Espacio interno para el módulo \gls{buck-converter} basado en LM2596
	\item Orificio para cable de alimentación hacia pack de baterías externo
	\item Provisión para conexión de antena externa
	\item Ranura de acceso a la tarjeta microSD
	\item Puntos de montaje para fijación en superficies
\end{itemize}

El plano 2D del diseño final se incluye en el Anexo~\ref{anexo:planos-carcasa}
(Figura~\ref{fig:plano-carcasa} y Figura~\ref{fig:plano-base}). El modelo 3D
modificado está disponible públicamente en Printables\footnote{\url{www.printables.com/model/1532349-case-for-esp32_cam-trail-camera-pir-sensor-buck-co}}.

\section{Nodo raíz (root-node)}

\subsection{Diseño del hardware}

El nodo raíz utiliza una placa de desarrollo ESP32 DevKit V1, sin
módulo de cámara, que actúa como puerta de enlace entre la red
\gls{mesh} y el servidor de aplicación.

\subsection{Firmware del nodo raíz}

El firmware del nodo raíz implementa:

\begin{itemize}
	\item Inicialización como nodo raíz de la red \gls{ESP-MESH}
	\item Recepción y reensamblado de imágenes fragmentadas desde los
	      nodos hijos
	\item Conexión Wi-Fi a un router doméstico para acceso a internet
	\item Cliente HTTP para envío de imágenes al servidor
\end{itemize}

\subsection{Conexión con servidor TCP}

El nodo raíz envía las imágenes recibidas al servidor de aplicación
mediante peticiones HTTP POST. Cada imagen se transmite como cuerpo
de la petición junto con metadatos (identificador del nodo origen,
timestamp).

La conexión al servidor se realiza a través de Wi-Fi conectado a un
router doméstico con acceso a internet. En la sección de trabajos
futuros se discute la posibilidad de reemplazar este enlace por
tecnologías de mayor alcance para despliegues en zonas remotas.

\subsection{Gestión de la red mesh}

El nodo raíz es responsable de:

\begin{itemize}
	\item Mantener la topología de la red mesh
	\item Gestionar la conexión y desconexión de nodos hijos
	\item Enrutar los datos desde cualquier nodo hasta sí mismo
	\item Proporcionar sincronización de tiempo a la red
\end{itemize}

La red está configurada para soportar hasta 6 niveles de profundidad,
aunque en las pruebas realizadas se utilizaron únicamente 3 nodos.

\section{Red mesh}

\subsection{Topología de la red}

La red \gls{ESP-MESH} se organiza en una topología de árbol donde:

\begin{description}
	\item[Nodo raíz:] Único punto de conexión con la red externa (router Wi-Fi)
	\item[Nodos intermedios:] Pueden existir nodos que actúen como repetidores
	\item[Nodos hoja:] Los nodos de cámara que capturan y transmiten imágenes
\end{description}

Cada nodo opera en modo \gls{AP-STA}, actuando simultáneamente como
punto de acceso para nodos hijos y como estación conectada a su nodo padre.

\subsection{Protocolo de comunicación}

La comunicación utiliza el protocolo \gls{ESP-MESH} implementado sobre
Wi-Fi 802.11, con las siguientes características:

\begin{itemize}
	\item Autoorganización: los nodos seleccionan su padre óptimo basándose
	      en \gls{rssi}
	\item \Gls{autocuracion}: reconexión automática ante fallos de nodos
	\item Soporte para mensajes unicast y broadcast
	\item Fragmentación y reensamblado de datos grandes mediante \gls{mwifi}
\end{itemize}

\subsection{Formato de datos}

Las imágenes se transmiten como datos binarios (\gls{jpeg}) precedidos
de un encabezado que incluye el tamaño total de la imagen y el
identificador del nodo origen.

\section{Servicio de detección (wildlife-detection)}

\subsection{Arquitectura del servicio}

El servicio de detección se implementa como un contenedor \gls{docker}
independiente que expone una \gls{api} REST para inferencia de imágenes.

\subsection{Contenedor Docker con SpeciesNet}

El contenedor incluye:

\begin{itemize}
	\item \gls{speciesnet} con modelos preentrenados
	\item \gls{megadetector} para detección de animales, personas y vehículos
	\item Modelos \gls{yolov5} para clasificación taxonómica
	\item Servidor HTTP basado en LitServe
\end{itemize}

\subsection{API de inferencia}

El servicio expone un endpoint \texttt{/predict} que:

\begin{enumerate}
	\item Recibe una imagen en formato \gls{jpeg}
	\item Ejecuta el pipeline de detección y clasificación
	\item Retorna las detecciones con \glspl{bounding-box}, confianzas y
	      etiquetas taxonómicas
\end{enumerate}

\subsection{Detección y clasificación}

El pipeline de \gls{speciesnet} opera en dos fases:

\begin{enumerate}
	\item \textbf{Detección:} \gls{megadetector} identifica regiones de
	      interés clasificándolas como animal, persona o vehículo.
	\item \textbf{Clasificación:} Para las regiones detectadas como animales,
	      se aplican modelos de clasificación taxonómica que predicen
	      familia, género y especie.
\end{enumerate}

\section{Servidor de aplicación (server)}

\subsection{Arquitectura Django}

El servidor de aplicación se desarrolló utilizando \gls{django}, implementando:

\begin{itemize}
	\item Endpoint HTTP para recepción de imágenes desde el nodo raíz
	\item Integración con el servicio de detección vía HTTP REST
	\item Almacenamiento de imágenes y metadatos
	\item Bot de Telegram para notificaciones
	\item Interfaz web para visualización de resultados
\end{itemize}

\subsection{Gestión de imágenes}

Las imágenes se almacenan en un volumen \gls{docker} compartido:

\begin{itemize}
	\item Imágenes originales recibidas desde los nodos
	\item Imágenes anotadas con \glspl{bounding-box} generadas por el
	      servicio de detección
\end{itemize}

En la base de datos se almacenan únicamente los paths a las imágenes
junto con los metadatos de detección.

\subsection{Bot de Telegram y sistema de alertas}

El sistema de alertas utiliza la librería \texttt{python-telegram-bot}
para enviar notificaciones cuando se detectan objetos de interés con
alto grado de confianza.

Cada notificación incluye:

\begin{itemize}
	\item Imagen original capturada por el nodo
	\item Imagen anotada con las \glspl{bounding-box} de las detecciones
	\item Información sobre cantidad y confianza de las detecciones
	\item Etiquetas de clasificación taxonómica de mayor confianza
\end{itemize}

\subsection{Base de datos PostgreSQL}

La base de datos \gls{postgresql} almacena:

\begin{itemize}
	\item Registros de imágenes con paths y timestamps
	\item Resultados de detección (clases, confianzas, coordenadas)
	\item Clasificaciones taxonómicas
	\item Configuración del sistema
\end{itemize}

\subsection{Despliegue con Docker Compose}

El servidor se despliega mediante \gls{docker-compose}, orquestando
los siguientes servicios:

\begin{itemize}
	\item Contenedor de la aplicación \gls{django}
	\item Contenedor de \gls{postgresql}
	\item Contenedor del servicio de detección con \gls{speciesnet}
\end{itemize}

\section{Alimentación y consumo energético}

Los nodos de cámara se alimentan mediante packs de \glspl{18650}
en configuración 2S (dos celdas en serie), proporcionando un voltaje
nominal de 7.4V. El módulo \gls{buck-converter} LM2596 reduce este
voltaje a 5V para alimentar el ESP32-CAM.

El consumo energético se midió en tres estados de operación:

\begin{description}
	\item[Modo \gls{power-save}:] Consumo reducido mientras el nodo espera
	      eventos, con transmisión Wi-Fi limitada pero CPU activo.
	\item[Captura de imagen:] Consumo elevado momentáneo durante la
	      activación de la cámara y compresión JPEG.
	\item[Transmisión:] Máximo consumo durante el envío de datos por
	      Wi-Fi a través de la red mesh.
\end{description}

Es importante destacar que el sistema utiliza el modo \gls{power-save}
de \gls{ESP-MDF} en lugar de \gls{deep-sleep}. El modo power save reduce el
consumo limitando el tiempo de transmisión Wi-Fi activa, mientras mantiene el
CPU funcionando para responder a eventos de la red y del sensor PIR.

% ==============================================================================
% Capítulo 8: Pruebas y Resultados
% ==============================================================================
\chapter{Pruebas y Resultados}

\section{Ambiente de pruebas}

\subsection{Configuración del hardware}

Las pruebas se realizaron utilizando la siguiente configuración de hardware:

\begin{itemize}
	\item 3 nodos de cámara (ESP32-CAM con sensor HC-SR501)
	\item 1 nodo raíz (ESP32 DevKit V1)
	\item Packs de \glspl{18650} en configuración 2S
	\item Router Wi-Fi doméstico para conexión a internet
	\item Servidor local con procesador multinúcleo para inferencia (sin GPU),
	      accesible mediante túnel VPN (Pangolin, basado en WireGuard) y proxy
	      reverso (Traefik)
\end{itemize}

% TODO: Agregar foto del hardware ensamblado
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=0.8\textwidth]{figures/hardware-ensamblado.jpg}
	\fbox{\parbox{0.8\textwidth}{\centering\vspace{3cm}
			[Foto del nodo de cámara ensamblado con carcasa 3D]
			\vspace{3cm}}}
	\caption{Nodo de cámara completamente ensamblado.}
	\label{fig:hardware-ensamblado}
\end{figure}

\subsection{Configuración del software}

El software se desplegó con la siguiente configuración:

\begin{itemize}
	\item Firmware compilado con \gls{ESP-IDF} v5.x y \gls{ESP-MDF}
	\item Contenedores \gls{docker} ejecutándose en servidor Linux
	\item Base de datos \gls{postgresql}
	\item Servicio de inferencia con \gls{speciesnet} y LitServe
	\item \Gls{telegram-bot} configurado para notificaciones
\end{itemize}

% TODO: Agregar screenshot del docker-compose corriendo
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=\textwidth]{figures/docker-compose-running.png}
	\fbox{\parbox{0.9\textwidth}{\centering\vspace{2cm}
			[Screenshot de docker-compose ps mostrando servicios activos]
			\vspace{2cm}}}
	\caption{Servicios del servidor ejecutándose mediante Docker Compose.}
	\label{fig:docker-compose-running}
\end{figure}

\section{Pruebas de laboratorio}

Las pruebas de laboratorio se realizaron en condiciones controladas de
interior, verificando el funcionamiento individual de cada componente
antes de la integración.

\subsection{Pruebas de captura de imagen}

Se verificó la correcta captura de imágenes por parte del módulo OV2640,
evaluando:

\begin{itemize}
	\item Inicialización correcta de la cámara
	\item Calidad de imagen a diferentes niveles de compresión
	\item Tamaño de archivo resultante (objetivo: $<$ 8 KB)
	\item Tiempo de captura y compresión
\end{itemize}

% TODO: Agregar ejemplos de imágenes capturadas
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=0.8\textwidth]{figures/ejemplo-captura.jpg}
	\fbox{\parbox{0.8\textwidth}{\centering\vspace{3cm}
			[Ejemplo de imagen capturada por el nodo - 640x480 JPEG]
			\vspace{3cm}}}
	\caption{Ejemplo de imagen capturada por un nodo de cámara.}
	\label{fig:ejemplo-captura}
\end{figure}

\subsection{Pruebas del sensor PIR}

Se evaluó el funcionamiento del sensor HC-SR501:

\begin{itemize}
	\item Respuesta a movimiento de personas a diferentes distancias
	\item Tiempo de respuesta desde detección hasta interrupción
	\item Configuración óptima de sensibilidad y retardo
	\item Tasa de falsas activaciones
\end{itemize}

% TODO: Agregar tabla con resultados de pruebas PIR
\begin{table}[htbp]
	\centering
	\caption{Resultados de pruebas del sensor PIR.}
	\label{tab:pruebas-pir}
	\begin{tabular}{lc}
		\hline
		\textbf{Parámetro}            & \textbf{Valor} \\
		\hline
		Distancia máxima de detección & [X] m          \\
		Tiempo de respuesta promedio  & [X] ms         \\
		Falsas activaciones por hora  & [X]            \\
		\hline
	\end{tabular}
\end{table}

\subsection{Pruebas de transmisión mesh}

Se verificó la transmisión de imágenes a través de la red \gls{mesh}:

\begin{itemize}
	\item Establecimiento de conexión entre nodos
	\item Transmisión exitosa de imágenes completas
	\item Tiempo de transmisión desde nodo hasta servidor
	\item Comportamiento ante pérdida de conexión
\end{itemize}

% TODO: Agregar screenshot del log de transmisión
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=\textwidth]{figures/log-transmision.png}
	\fbox{\parbox{0.9\textwidth}{\centering\vspace{2cm}
			[Screenshot del monitor serial mostrando transmisión exitosa]
			\vspace{2cm}}}
	\caption{Log de transmisión de imagen a través de la red mesh.}
	\label{fig:log-transmision}
\end{figure}

\subsection{Pruebas del sistema de clasificación}

Se evaluó el pipeline de detección y clasificación con imágenes de prueba:

\begin{itemize}
	\item Detección correcta de animales, personas y vehículos
	\item Precisión de las \glspl{bounding-box}
	\item \Gls{clasificacion-taxonomica} de animales detectados
	\item Tiempo de inferencia por imagen
\end{itemize}

% TODO: Agregar ejemplo de imagen procesada con detecciones
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=0.8\textwidth]{figures/ejemplo-deteccion.jpg}
	\fbox{\parbox{0.8\textwidth}{\centering\vspace{3cm}
			[Imagen anotada con bounding boxes y etiquetas de clasificación]
			\vspace{3cm}}}
	\caption{Ejemplo de imagen procesada por el sistema de detección.}
	\label{fig:ejemplo-deteccion}
\end{figure}

\subsection{Pruebas del sistema de alertas}

Se verificó el funcionamiento del bot de Telegram:

\begin{itemize}
	\item Recepción correcta de notificaciones
	\item Envío de imagen original y anotada
	\item Información de detecciones y clasificaciones
	\item Tiempo desde captura hasta notificación
\end{itemize}

% TODO: Agregar screenshot de notificación de Telegram
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=0.6\textwidth]{figures/telegram-notificacion.png}
	\fbox{\parbox{0.6\textwidth}{\centering\vspace{4cm}
			[Screenshot de notificación de Telegram con imágenes y detecciones]
			\vspace{4cm}}}
	\caption{Notificación recibida en Telegram con resultados de detección.}
	\label{fig:telegram-notificacion}
\end{figure}

\section{Pruebas de campo}

\subsection{Configuración del entorno}

Las pruebas de campo se realizaron en un entorno exterior, instalando
los nodos de cámara en ubicaciones representativas de un despliegue real.

% TODO: Agregar foto del despliegue en campo
\begin{figure}[htbp]
	\centering
	% \includegraphics[width=0.8\textwidth]{figures/despliegue-campo.jpg}
	\fbox{\parbox{0.8\textwidth}{\centering\vspace{3cm}
			[Foto de nodo instalado en árbol/poste en entorno exterior]
			\vspace{3cm}}}
	\caption{Nodo de cámara desplegado en entorno de pruebas de campo.}
	\label{fig:despliegue-campo}
\end{figure}

\subsection{Condiciones de las pruebas}

Las pruebas de campo se realizaron bajo las siguientes condiciones:

\begin{itemize}
	\item Duración: [X] horas de operación continua
	\item Condiciones climáticas: [describir condiciones]
	\item Número de nodos desplegados: 3
	\item Distancia entre nodos: [X] metros
	\item Distancia al router Wi-Fi: [X] metros
\end{itemize}

\subsection{Resultados obtenidos}

Durante las pruebas de campo se registraron los siguientes resultados:

% TODO: Completar con datos reales
\begin{itemize}
	\item Imágenes capturadas: [X]
	\item Detecciones exitosas: [X]
	\item Falsas activaciones: [X]
	\item Tiempo de operación sin fallos: [X] horas
\end{itemize}

\section{Métricas de rendimiento de red}

\subsection{Latencia de transmisión}

Se midió el tiempo transcurrido desde la captura de imagen hasta la
recepción en el servidor:

% TODO: Agregar tabla con mediciones de latencia
\begin{table}[htbp]
	\centering
	\caption{Latencia de transmisión medida.}
	\label{tab:latencia}
	\begin{tabular}{lc}
		\hline
		\textbf{Métrica}    & \textbf{Valor} \\
		\hline
		Latencia mínima     & [X] s          \\
		Latencia promedio   & [X] s          \\
		Latencia máxima     & [X] s          \\
		Desviación estándar & [X] s          \\
		\hline
	\end{tabular}
\end{table}

\subsection{Distancia máxima entre nodos}

Se evaluó la distancia máxima a la cual los nodos pueden mantener
conexión estable:

% TODO: Agregar resultados de pruebas de distancia
\begin{table}[htbp]
	\centering
	\caption{Distancia máxima entre nodos.}
	\label{tab:distancia}
	\begin{tabular}{lc}
		\hline
		\textbf{Condición}          & \textbf{Distancia máxima} \\
		\hline
		Línea de vista directa      & [X] m                     \\
		Con obstáculos (vegetación) & [X] m                     \\
		Interior (paredes)          & [X] m                     \\
		\hline
	\end{tabular}
\end{table}

\subsection{Estabilidad de la conexión}

Se monitoreó la estabilidad de la red durante operación prolongada:

\begin{itemize}
	\item Número de reconexiones: [X]
	\item Paquetes perdidos: [X]\%
	\item Tiempo de reconexión promedio: [X] s
\end{itemize}

\section{Métricas de clasificación}

\subsection{Precisión de detección}

Se evaluó la precisión del sistema para detectar los diferentes tipos
de objetos:

% TODO: Agregar tabla de precisión de detección
\begin{table}[htbp]
	\centering
	\caption{Precisión de detección por categoría.}
	\label{tab:precision-deteccion}
	\begin{tabular}{lccc}
		\hline
		\textbf{Categoría} & \textbf{Verdaderos +} & \textbf{Falsos +} & \textbf{Precisión} \\
		\hline
		Animales           & [X]                   & [X]               & [X]\%              \\
		Personas           & [X]                   & [X]               & [X]\%              \\
		Vehículos          & [X]                   & [X]               & [X]\%              \\
		Vacías             & [X]                   & [X]               & [X]\%              \\
		\hline
	\end{tabular}
\end{table}

\subsection{Precisión de clasificación taxonómica}

Para las imágenes con animales detectados, se evaluó la precisión de
la clasificación taxonómica:

% TODO: Agregar resultados de clasificación taxonómica
\begin{table}[htbp]
	\centering
	\caption{Precisión de clasificación taxonómica.}
	\label{tab:precision-taxonomica}
	\begin{tabular}{lc}
		\hline
		\textbf{Nivel taxonómico} & \textbf{Precisión} \\
		\hline
		Familia                   & [X]\%              \\
		Género                    & [X]\%              \\
		Especie                   & [X]\%              \\
		\hline
	\end{tabular}
\end{table}

\section{Métricas de consumo energético}

\subsection{Consumo promedio del nodo}

Se midió el consumo eléctrico del nodo en diferentes estados de operación:

% TODO: Agregar tabla de consumo energético
\begin{table}[htbp]
	\centering
	\caption{Consumo energético por estado de operación.}
	\label{tab:consumo}
	\begin{tabular}{lc}
		\hline
		\textbf{Estado}            & \textbf{Consumo (mA)} \\
		\hline
		Modo \gls{power-save}      & [X]                   \\
		Captura de imagen          & [X]                   \\
		Transmisión Wi-Fi          & [X]                   \\
		Consumo promedio ponderado & [X]                   \\
		\hline
	\end{tabular}
\end{table}

\subsection{Autonomía estimada}

Basándose en el consumo promedio y la capacidad de las baterías:

% TODO: Completar cálculo de autonomía
\begin{itemize}
	\item Capacidad del pack 2S: [X] mAh
	\item Consumo promedio: [X] mA
	\item Autonomía teórica: [X] horas
	\item Autonomía medida en pruebas: [X] horas
\end{itemize}

\section{Análisis de resultados}

Los resultados obtenidos demuestran la viabilidad del sistema propuesto
para el monitoreo de áreas protegidas. A continuación se presenta un
análisis de los principales hallazgos:

\subsection{Cumplimiento de objetivos}

% TODO: Completar análisis de cumplimiento
\begin{description}
	\item[Detección de fauna:] [Análisis del desempeño en detección]
	\item[Latencia de respuesta:] [Análisis de tiempos de respuesta]
	\item[Cobertura de red:] [Análisis de alcance y estabilidad]
	\item[Autonomía energética:] [Análisis de consumo y duración]
\end{description}

\subsection{Limitaciones observadas}

Durante las pruebas se identificaron las siguientes limitaciones:

\begin{itemize}
	\item Limitación 1 observada
	\item Limitación 2 observada
	\item Limitación 3 observada
\end{itemize}

\subsection{Comparación con objetivos planteados}

% TODO: Agregar tabla comparativa
\begin{table}[htbp]
	\centering
	\caption{Comparación de resultados con objetivos planteados.}
	\label{tab:comparacion-objetivos}
	\begin{tabular}{lcc}
		\hline
		\textbf{Métrica}       & \textbf{Objetivo} & \textbf{Resultado} \\
		\hline
		Latencia de respuesta  & < X min           & [X] min            \\
		Precisión de detección & > X\%             & [X]\%              \\
		Autonomía              & > X horas         & [X] horas          \\
		Cobertura              & > X m             & [X] m              \\
		\hline
	\end{tabular}
\end{table}

% ==============================================================================
% Capítulo 9: Conclusiones
% ==============================================================================
\chapter{Conclusiones}

\section{Conclusiones generales}

El presente trabajo demostró la viabilidad técnica de un sistema de
monitoreo de bajo costo para áreas protegidas, basado en nodos de cámara
con conectividad \gls{mesh} y clasificación automática de imágenes
mediante \gls{ia}.

Los principales logros alcanzados incluyen:

\begin{itemize}
	\item Se diseñó e implementó un sistema completo de monitoreo que
	      integra hardware de bajo costo (\gls{ESP32}-CAM, sensores \gls{pir}) con
	      tecnologías de \gls{ia} de vanguardia (\gls{speciesnet},
	      \gls{megadetector}).

	\item Se logró reducir significativamente el tiempo de procesamiento
	      de imágenes desde días o semanas ---típico de las \glspl{camara-trampa}
	      tradicionales--- a minutos, habilitando respuestas operativas
	      antes imposibles.

	\item Se demostró que las redes \gls{mesh} basadas en \gls{ESP-MESH}
	      son una alternativa viable para extender la cobertura de monitoreo
	      en áreas sin infraestructura de red, manteniendo la capacidad de
	      transmitir imágenes.

	\item Se validó la integración de modelos de detección y clasificación
	      taxonómica en un pipeline de procesamiento automatizado, capaz de
	      distinguir entre fauna, personas y vehículos.

	\item Se implementó un sistema de alertas en tiempo operativo mediante
	      Telegram, proporcionando notificaciones inmediatas con imágenes
	      anotadas y clasificaciones a los usuarios finales.
\end{itemize}

El costo total de los componentes de hardware para un nodo de cámara se
mantiene significativamente por debajo de las cámaras trampa comerciales
con capacidades similares de conectividad, validando la propuesta de un
sistema de bajo costo accesible para proyectos de conservación con
recursos limitados.

\section{Aportes del trabajo}

Este trabajo realiza los siguientes aportes:

\begin{description}
	\item[Arquitectura de sistema integrado:] Se propone una arquitectura
	      que combina captura distribuida, transmisión mesh y procesamiento
	      centralizado con \gls{ia}, aplicable a diversos escenarios de
	      monitoreo ambiental.

	\item[Prototipo funcional de bajo costo:] Se desarrolló un prototipo
	      completo y funcional utilizando componentes comerciales de bajo
	      costo, con diseños de carcasa listos para fabricación mediante
	      impresión 3D.

	\item[Integración de SpeciesNet en pipeline de tiempo operativo:] Se
	      demostró la viabilidad de utilizar modelos de clasificación
	      taxonómica entrenados en grandes datasets de \glspl{camara-trampa}
	      en un sistema de respuesta rápida.

	\item[Código abierto:] Todo el código desarrollado (firmware, servidor,
	      servicio de detección) está disponible en repositorios públicos de
	      GitHub, permitiendo la reproducción y extensión del trabajo por
	      parte de otros investigadores y desarrolladores.
\end{description}

\section{Trabajos futuros}

A partir de los resultados obtenidos, se identifican las siguientes
líneas de trabajo futuro:

\begin{description}
	\item[Visión nocturna:] Incorporar módulos de cámara con capacidad
	      infrarroja para permitir la captura de imágenes durante la noche,
	      extendiendo significativamente la utilidad del sistema para
	      monitoreo de fauna con hábitos nocturnos.

	\item[Conectividad de largo alcance:] Reemplazar el enlace Wi-Fi entre
	      el nodo raíz y el servidor por tecnologías de mayor alcance como
	      LoRa, redes celulares (4G/LTE) o enlaces satelitales, permitiendo
	      despliegues en zonas remotas sin cobertura de internet convencional.

	\item[Optimización del consumo energético:] Investigar estrategias
	      adicionales de ahorro de energía, incluyendo paneles solares y
	      algoritmos de gestión de batería más sofisticados.

	\item[Implementación de nodo rama:] Una alternativa considerada pero no
	      implementada ---para reducir la complejidad del prototipo--- es el
	      diseño de un tercer tipo de nodo: un ``nodo rama'' o repetidor
	      dedicado que mantendría la red mesh activa. Esto permitiría que
	      los nodos de cámara funcionen como nodos hoja y utilicen el modo
	      \gls{deep-sleep} verdadero, despertando únicamente ante
	      interrupciones del sensor \gls{pir}, conectándose brevemente a la
	      red para transmitir la imagen, y volviendo a dormir. Esta
	      arquitectura podría reducir drásticamente el consumo promedio de
	      los nodos de cámara.

	\item[Procesamiento en el borde:] Explorar la posibilidad de realizar
	      inferencia directamente en los nodos de cámara utilizando modelos
	      optimizados (TinyML), reduciendo el volumen de datos transmitidos
	      y la latencia de respuesta.

	\item[Mejoras en clasificación:] Entrenar o afinar modelos específicos
	      para la fauna de la región del Bosque Atlántico, mejorando la
	      precisión de clasificación para especies locales.

	\item[Interfaz de usuario:] Desarrollar una interfaz web más completa
	      que permita visualización en mapa, gestión de múltiples despliegues
	      y generación de reportes automatizados.
\end{description}

\section{Recomendaciones}

Basándose en la experiencia adquirida durante el desarrollo y pruebas
del sistema, se realizan las siguientes recomendaciones para futuras
implementaciones:

\begin{enumerate}
	\item \textbf{Selección de ubicaciones:} Considerar cuidadosamente la
	      distancia entre nodos y la presencia de obstáculos al planificar
	      el despliegue. La vegetación densa reduce significativamente el
	      alcance de la señal Wi-Fi.

	\item \textbf{Protección contra elementos:} Para despliegues de largo
	      plazo, utilizar materiales de impresión 3D resistentes a la
	      intemperie (\gls{petg} o \gls{asa}) y considerar el uso de
	      selladores adicionales.

	\item \textbf{Capacidad de batería:} Dimensionar los packs de baterías
	      según la frecuencia esperada de activaciones y la autonomía deseada.
	      El diseño del prototipo con \gls{buck-converter} permite alimentación
	      desde un amplio rango de voltajes de entrada (4.5V-40V), facilitando
	      el uso de packs de \glspl{18650} en diversas configuraciones
	      (2S, 3S, 4S).

	\item \textbf{Selección del sensor de movimiento:} El sensor \gls{pir}
	      domótico utilizado en el prototipo (HC-SR501) está optimizado para
	      detectar personas y puede no activarse consistentemente ante fauna
	      de menor porte. Para despliegues enfocados en monitoreo de fauna
	      silvestre, se recomienda evaluar sensores \gls{pir} de mayor
	      sensibilidad o tecnologías alternativas de detección de movimiento
	      diseñadas para aplicaciones de vida silvestre.

	\item \textbf{Monitoreo remoto:} Implementar sistemas de monitoreo de
	      estado de los nodos (nivel de batería, conectividad) para
	      identificar problemas antes de que resulten en pérdida de datos.
\end{enumerate}

% ==============================================================================
% Referencias
% ==============================================================================
\printbibliography[heading=bibnumbered]

% ==============================================================================
% Anexos
% ==============================================================================
\appendix

\chapter{Esquemáticos del hardware}

\chapter{Planos de la carcasa}
\label{anexo:planos-carcasa}

\begin{figure}[htbp]
	\centering
	\includegraphics[height=0.85\textheight]{img/ESP3-CAM Drawing Main Case.pdf}
	\caption{Plano 2D de la carcasa principal del nodo de cámara.}
	\label{fig:plano-carcasa}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[height=0.85\textheight]{img/ESP3-CAM Drawing Base.pdf}
	\caption{Plano 2D de la base del nodo de cámara.}
	\label{fig:plano-base}
\end{figure}

\chapter{Código fuente relevante}

\section{Firmware del nodo mesh}

El archivo principal del firmware del nodo mesh (\texttt{mesh\_node.c}) contiene
la lógica de inicialización, captura de imágenes, detección de movimiento y
comunicación con la red mesh. El código~\ref{lst:app-main} presenta la función
principal \texttt{app\_main()} que inicializa todos los componentes del sistema.

\lstinputlisting[firstline=634, lastline=730, firstnumber=634, caption={Función principal \texttt{app\_main()} del nodo mesh.}, label=lst:app-main]{src/mesh-node-capstone-project/main/mesh_node.c}

El código~\ref{lst:capture-photo} muestra la función
\texttt{capture\_and\_save\_photo()}, responsable de capturar una imagen,
guardarla en la tarjeta SD y transmitirla a través de la red mesh.

\lstinputlisting[firstline=419, lastline=483, firstnumber=419, caption={Función de captura y envío de imágenes.}, label=lst:capture-photo]{src/mesh-node-capstone-project/main/mesh_node.c}

\section{Firmware del nodo raíz}
\section{Servidor de detección}
\section{Aplicación Django}

\chapter{Manual de instalación y uso}

Este capítulo presenta las instrucciones detalladas para la configuración e
instalación del sistema completo, incluyendo el firmware de los nodos, el
servidor de aplicación y el bot de Telegram.

\section{Configuración del firmware}

La configuración del firmware para los nodos mesh y el nodo raíz se realiza
mediante el menú de configuración de ESP-IDF. Los parámetros principales
se encuentran bajo el submenú ``Example Configuration'' accesible mediante
el comando \texttt{idf.py menuconfig}.

\subsection{Parámetros de la red Wi-Fi}

Los siguientes parámetros deben configurarse para conectar la red mesh a
un router externo que proporcione acceso a Internet:

\begin{description}
	\item[Router SSID:] Nombre de la red Wi-Fi del router.
	\item[Router Password:] Contraseña de la red Wi-Fi.
	\item[Router Channel:] Canal de operación del router. Si se desconoce,
	      configurar como 0 para detección automática.
\end{description}

\subsection{Parámetros de la red ESP-MESH}

La red mesh se configura mediante los siguientes parámetros:

\begin{description}
	\item[Mesh ID:] Identificador único de la red mesh (6 bytes).
	\item[Mesh Password:] Contraseña de la red mesh (entre 8 y 64 caracteres).
	      Si se deja en blanco, la red no estará encriptada.
	\item[Max Connections:] Número máximo de conexiones que puede aceptar
	      cada nodo (por defecto, 6).
\end{description}

\subsection{Parámetros del servidor TCP}

Para que el nodo raíz pueda conectarse al servidor de aplicación, se
deben configurar:

\begin{description}
	\item[Server IP:] Dirección IP del servidor donde se ejecuta la
	      aplicación Django.
	\item[Server Port:] Puerto TCP del servidor (por defecto, 8001).
\end{description}

\subsection{Compilación y grabación}

Una vez configurados los parámetros, el firmware se compila y graba
utilizando los siguientes comandos:

\begin{lstlisting}[language=bash, caption={Comandos para compilar y grabar el firmware.}]
# Borrar flash y grabar firmware
idf.py erase_flash flash monitor -b 921600 -p /dev/ttyUSB0
\end{lstlisting}

Es recomendable grabar primero el nodo raíz y verificar su conexión al
router antes de grabar los nodos de cámara.

\section{Despliegue del servidor}

El servidor de aplicación se despliega utilizando \gls{docker} y
Docker Compose, lo que simplifica la gestión de dependencias y la
configuración del entorno.

\subsection{Prerrequisitos}

\begin{itemize}
	\item Docker y Docker Compose instalados en el servidor.
	\item Token del bot de Telegram (obtenido de @BotFather).
	\item Opcional: GPU NVIDIA con nvidia-container-toolkit para
	      acelerar la inferencia.
\end{itemize}

\subsection{Configuración del entorno}

\begin{enumerate}
	\item Clonar el repositorio del servidor.
	\item Copiar el archivo de configuración de ejemplo:
	      \lstinline[language=bash]{cp .env.sample .env}
	\item Editar el archivo \texttt{.env} con los valores apropiados.
\end{enumerate}

Las variables de entorno principales son:

\begin{description}
	\item[DJANGO\_SECRET\_KEY:] Clave secreta de Django para producción.
	\item[POSTGRES\_DB, POSTGRES\_USER, POSTGRES\_PASSWORD:] Credenciales
	      de la base de datos PostgreSQL.
	\item[TELEGRAM\_BOT\_TOKEN:] Token del bot de Telegram (requerido).
	\item[GUNICORN\_WORKERS:] Número de workers de Gunicorn (por defecto, 2).
\end{description}

\subsection{Inicio de los servicios}

El sistema completo se inicia con un único comando:

\begin{lstlisting}[language=bash, caption={Inicio de los servicios con Docker Compose.}]
docker compose up --build
\end{lstlisting}

Este comando inicia cuatro servicios:

\begin{description}
	\item[web:] Servidor de aplicación Django (puerto 8000).
	\item[bot:] Bot de Telegram para notificaciones.
	\item[speciesnet:] Servicio de inferencia de \gls{speciesnet}
	      (puerto 8002).
	\item[db:] Base de datos PostgreSQL.
\end{description}

\textbf{Nota:} La primera ejecución puede tardar entre 5 y 10 minutos
mientras se descarga el modelo de \gls{speciesnet} ($\sim$2~GB). Las
ejecuciones posteriores son significativamente más rápidas gracias al
caché del modelo en un volumen de Docker.

\subsection{Aceleración por GPU}

Para habilitar la aceleración por GPU en el servicio de \gls{speciesnet}:

\begin{enumerate}
	\item Instalar nvidia-container-toolkit en el servidor.
	\item Descomentar la sección \texttt{deploy} del servicio
	      \texttt{speciesnet} en \texttt{docker-compose.yml}.
	\item Reiniciar los servicios.
\end{enumerate}

Con GPU, el tiempo de inferencia se reduce de 1--5 segundos por imagen
(CPU) a 0.5--1 segundo (GPU).

\section{Configuración del bot de Telegram}

El bot de Telegram permite recibir notificaciones en tiempo real y
consultar las últimas imágenes procesadas desde cualquier dispositivo
móvil.

\subsection{Creación del bot}

\begin{enumerate}
	\item Abrir Telegram y buscar @BotFather.
	\item Enviar el comando \texttt{/newbot} y seguir las instrucciones.
	\item Copiar el token proporcionado por BotFather.
	\item Configurar el token en la variable \texttt{TELEGRAM\_BOT\_TOKEN}
	      del archivo \texttt{.env}.
\end{enumerate}

\subsection{Registro de usuarios}

Para recibir notificaciones, los usuarios deben registrarse enviando
el comando \texttt{/start} al bot. Esto crea un registro en la base
de datos que asocia el ID de Telegram del usuario con el sistema.

\subsection{Comandos disponibles}

El bot soporta los siguientes comandos:

\begin{description}
	\item[/start:] Registra al usuario y muestra el mensaje de bienvenida.
	\item[/last:] Recupera la última imagen procesada, mostrando:
	      \begin{itemize}
		      \item Fotografía original.
		      \item Fotografía procesada con cuadros delimitadores.
		      \item Lista de detecciones con niveles de confianza.
		      \item Top 5 de clasificaciones de especies.
	      \end{itemize}
\end{description}

\section{Uso del sistema}

Una vez desplegado el sistema, el flujo de operación es completamente
automático. A continuación se describen las distintas formas de
interactuar con el sistema.

\subsection{Interfaz web}

La interfaz web está disponible en \texttt{http://<servidor>:8000} y
permite:

\begin{enumerate}
	\item Visualizar las imágenes recibidas de los nodos.
	\item Ver los resultados de la detección y clasificación.
	\item Acceder a las imágenes anotadas con cuadros delimitadores.
\end{enumerate}

\subsection{Notificaciones automáticas}

Cuando un nodo de cámara detecta movimiento y captura una imagen:

\begin{enumerate}
	\item La imagen se transmite a través de la red mesh hasta el
	      nodo raíz.
	\item El nodo raíz reenvía la imagen al servidor vía TCP.
	\item El servidor procesa la imagen con \gls{speciesnet}.
	\item Si se detectan animales, personas o vehículos, se envía
	      una notificación a todos los usuarios registrados en
	      Telegram.
\end{enumerate}

\subsection{Consultas bajo demanda}

Los usuarios pueden consultar el estado del sistema en cualquier
momento utilizando el comando \texttt{/last} del bot de Telegram,
que devuelve la última imagen procesada junto con su análisis.

\subsection{Acceso directo a la API}

Para integraciones avanzadas, es posible realizar consultas directas
al servicio de \gls{speciesnet}:

\begin{lstlisting}[language=bash, caption={Ejemplo de consulta directa a la API de SpeciesNet.}]
curl -X POST http://localhost:8002/predict \
  -H "Content-Type: application/json" \
  -d '{"instances": [{"filepath": "/app/media/images/foto.jpg"}]}'
\end{lstlisting}

La respuesta incluye:

\begin{description}
	\item[detections:] Lista de objetos detectados con etiquetas
	      (animal/humano/vehículo) y niveles de confianza.
	\item[classifications:] Predicciones de especies con niveles
	      de confianza.
	\item[annotated\_filepath:] Ruta a la imagen anotada con
	      cuadros delimitadores.
\end{description}

\subsection{Solución de problemas comunes}

\begin{description}
	\item[SpeciesNet no responde:] Verificar el estado del contenedor
	      con \lstinline[language=bash]{docker compose logs speciesnet}.
	      La descarga del modelo puede tardar varios minutos en la primera
	      ejecución.
	\item[Bot de Telegram sin respuesta:] Verificar que el token
	      esté configurado correctamente en \texttt{.env} y revisar
	      los logs con \lstinline[language=bash]{docker compose logs bot}.
	\item[Imágenes no procesadas:] Verificar que todos los servicios
	      estén en ejecución con \lstinline[language=bash]{docker compose ps}
	      y revisar los logs del servicio web.
\end{description}

\chapter{Análisis de viabilidad económica}

El presente anexo desarrolla un análisis de viabilidad económica del
sistema propuesto, evaluando su potencial como emprendimiento comercial
para la provisión de servicios de monitoreo de fauna silvestre y
detección de intrusos.

\section{Modelo de negocio}

El modelo de negocio propuesto se basa en dos fuentes de ingreso:

\begin{description}
	\item[Cobro por instalación:] Un pago inicial por parte del cliente
	      que cubre el costo del hardware (nodos de cámara y nodo raíz),
	      la instalación física del sistema en el sitio del cliente, y
	      la configuración inicial del servicio.
	\item[Suscripción mensual:] Un cobro recurrente que incluye el acceso
	      al servicio de procesamiento de imágenes con \gls{ia}, el
	      almacenamiento de imágenes en la nube, las notificaciones vía
	      \gls{telegram-bot}, y el soporte técnico.
\end{description}

Este modelo permite recuperar los costos de hardware en el momento de
la venta, mientras que la suscripción genera ingresos recurrentes que
aumentan con cada nuevo cliente, creando un flujo de caja predecible
y creciente.

\section{Segmentación de mercado}

El mercado objetivo se compone de dos segmentos principales en la
provincia de Misiones, Argentina, como se detalla en la
Tabla~\ref{tab:segmentacion-mercado}.

\begin{table}[htbp]
	\centering
	\caption{Segmentación del mercado objetivo.}
	\label{tab:segmentacion-mercado}
	\begin{tblr}{
			colspec = {X[l] r},
			row{1} = {font=\bfseries},
			hlines,
		}
		Segmento                       & Cantidad \\
		Reservas naturales en Misiones & 116      \\
		\Gls{eap} con bosques y montes & 10,802   \\
		{Total mercado potencial}      & 10,918   \\
		{Mercado alcanzado (objetivo)} & 150      \\
		{Porcentaje del mercado}       & 1.37\%   \\
	\end{tblr}
\end{table}

La proyección considera alcanzar 28 nuevos clientes por año durante
los primeros 5 años de operación, llegando a 140 clientes activos al
final del período analizado.

\section{Costos fijos}

Los costos fijos mensuales contemplan los gastos operativos necesarios
para mantener la operación del emprendimiento, detallados en la
Tabla~\ref{tab:costos-fijos}.

\begin{table}[htbp]
	\centering
	\caption{Estructura de costos fijos.}
	\label{tab:costos-fijos}
	\begin{tblr}{
			colspec = {X[l] r r},
			row{1} = {font=\bfseries},
			row{11} = {font=\bfseries},
			hlines,
		}
		Concepto     & Mensual (USD) & Anual (USD) \\
		Alquiler     & 150.00        & 1,800.00    \\
		Electricidad & 100.00        & 1,200.00    \\
		Agua         & 30.00         & 360.00      \\
		Dominio      & 3.00          & 36.00       \\
		Hosting      & 5.00          & 60.00       \\
		Internet     & 22.00         & 264.00      \\
		Sueldos      & 400.00        & 4,800.00    \\
		Teléfono     & 8.00          & 96.00       \\
		Seguros      & 15.00         & 180.00      \\
		Total        & 733.00        & 8,796.00    \\
	\end{tblr}
\end{table}

\section{Costos variables}

Los costos variables se estructuran en tres categorías según el tipo
de producto o servicio:

\subsection{Suscripción mensual}

La Tabla~\ref{tab:cv-suscripcion} detalla el costo de provisión del
servicio por cada susciptor activo.

\begin{table}[htbp]
	\centering
	\caption{Costos variables por suscripción.}
	\label{tab:cv-suscripcion}
	\begin{tblr}{
		colspec = {X[l] r},
		row{1} = {font=\bfseries},
		row{4,5,6} = {font=\bfseries},
				hlines,
			}
		Componente            & Costo (USD) \\
		API de inferencia     & 2.00        \\
		Hosting base de datos & 1.00        \\
		Costo total           & 3.00        \\
		Precio venta          & 50.00       \\
		Margen bruto          & 1,567\%     \\
	\end{tblr}
\end{table}

\subsection{Nodo de cámara}

La Tabla~\ref{tab:cv-camara} presenta el desglose de costos de fabricación
de cada nodo de cámara.

\begin{table}[htbp]
	\centering
	\caption{Costos variables por nodo de cámara.}
	\label{tab:cv-camara}
	\begin{tblr}{
		colspec = {X[l] r},
		row{1} = {font=\bfseries},
		row{14,15,16} = {font=\bfseries},
				hlines,
			}
		Componente           & Costo (USD) \\
		ESP32-CAM            & 9.00        \\
		\Glspl{18650}        & 18.00       \\
		PCB                  & 1.00        \\
		Sensor PIR           & 1.00        \\
		Cables               & 1.00        \\
		Estaño               & 1.00        \\
		Conectores           & 3.00        \\
		Filamento \gls{pla}  & 3.00        \\
		Abrazaderas          & 5.00        \\
		Insertos             & 1.00        \\
		Tornillos            & 1.00        \\
		\Gls{buck-converter} & 1.00        \\
		Costo total          & 45.00       \\
		Precio venta         & 75.00       \\
		Margen bruto         & 67\%        \\
	\end{tblr}
\end{table}

\subsection{Nodo raíz}

La Tabla~\ref{tab:cv-raiz} muestra los costos asociados a cada nodo raíz.

\begin{table}[htbp]
	\centering
	\caption{Costos variables por nodo raíz.}
	\label{tab:cv-raiz}
	\begin{tblr}{
		colspec = {X[l] r},
		row{1} = {font=\bfseries},
		row{8,9,10} = {font=\bfseries},
				hlines,
			}
		Componente          & Costo (USD) \\
		ESP32 DevKit        & 3.00        \\
		Cables              & 1.00        \\
		Estaño              & 1.00        \\
		Filamento \gls{pla} & 3.00        \\
		Insertos            & 1.00        \\
		Tornillos           & 1.00        \\
		Costo total         & 10.00       \\
		Precio venta        & 100.00      \\
		Margen bruto        & 900\%       \\
	\end{tblr}
\end{table}

\section{Bienes de capital}

La inversión inicial contempla la adquisición de equipamiento para
fabricación, logística y operaciones, según se detalla en la
Tabla~\ref{tab:bienes-capital}.

\begin{table}[htbp]
	\centering
	\caption{Inversión en bienes de capital.}
	\label{tab:bienes-capital}
	\begin{tblr}{
		colspec = {X[l] r c},
		row{1} = {font=\bfseries},
		row{9,11} = {font=\bfseries},
				hlines,
			}
		Concepto             & Precio (USD) & Amortización (años) \\
		Camioneta            & 15,000.00    & 5                   \\
		Impresora 3D         & 450.00       & 3                   \\
		Ploteo               & 100.00       & 3                   \\
		PC de Escritorio     & 200.00       & 3                   \\
		Insumos de Oficina   & 1,000.00     & 3                   \\
		Estación de Soldado  & 150.00       & 3                   \\
		Multímetro           & 30.00        & 3                   \\
		Total equipos        & 16,930.00    &                     \\
		Mano de obra inicial & 3,600.00     & (240 hs × \$15/h)   \\
		Inversión total      & 20,530.00    &                     \\
	\end{tblr}
\end{table}

\section{Flujo de caja operativo}

El flujo de caja operativo proyecta los ingresos y egresos sin considerar
financiamiento externo, como se presenta en la Tabla~\ref{tab:flujo-operativo}.

\begin{table}[htbp]
	\centering
	\caption{Flujo de caja operativo proyectado (USD).}
	\label{tab:flujo-operativo}
	\small
	\begin{tblr}{
		colspec = {X[l] r r r r r r},
		row{1} = {font=\bfseries},
		row{15,16} = {font=\bfseries},
				hlines,
			}
		Concepto             & Año 0   & Año 1   & Año 2   & Año 3   & Año 4   & Año 5   \\
		Suscripciones acum.  &         & 28      & 56      & 84      & 112     & 140     \\
		Cámaras vendidas     &         & 280     & 280     & 280     & 280     & 280     \\
		Nodos raíz vendidos  &         & 28      & 28      & 28      & 28      & 28      \\
		Ingreso total        &         & 25,200  & 26,600  & 28,000  & 29,400  & 30,800  \\
		Costo total          &         & -21,760 & -21,844 & -21,928 & -22,012 & -22,096 \\
		Amortización         &         & -3,643  & -3,643  & -3,643  & -3,000  & -3,000  \\
		Resultado antes imp. &         & -203    & 1,113   & 2,429   & 4,388   & 5,704   \\
		Impuesto ganancias   &         & 0       & -389    & -850    & -1,536  & -1,996  \\
		Resultado neto       &         & -203    & 723     & 1,579   & 2,852   & 3,708   \\
		Inversión inicial    & -20,530 &         &         &         &         &         \\
		Recupero IVA         &         & 3,150   &         &         &         &         \\
		Valor residual       &         &         &         &         &         & 4,233   \\
		Flujo de caja        & -20,530 & 6,590   & 4,367   & 5,222   & 5,852   & 6,708   \\
		Acumulado            & -20,530 & -13,940 & -9,573  & -4,351  & 1,501   & 8,208   \\
	\end{tblr}
\end{table}

El período de recupero de la inversión se alcanza durante el \textbf{Año 4}.

\section{Flujo de caja del inversionista}

El análisis considera un financiamiento parcial mediante préstamo
bancario bajo el sistema francés de amortización:

\begin{table}[htbp]
	\centering
	\caption{Condiciones del financiamiento.}
	\label{tab:financiamiento}
	\begin{tblr}{
			colspec = {X[l] r},
			row{1} = {font=\bfseries},
			row{7} = {font=\bfseries},
			hlines,
		}
		Parámetro               & Valor         \\
		Monto del préstamo      & 15,000.00 USD \\
		Plazo                   & 5 años        \\
		Tasa de interés         & 5\% anual     \\
		Cuota anual             & 3,464.62 USD  \\
		Sistema de amortización & Francés       \\
		Inversión propia        & 5,530.00 USD  \\
	\end{tblr}
\end{table}
La Tabla~\ref{tab:financiamiento} resume las condiciones del préstamo
y la Tabla~\ref{tab:flujo-inversionista} presenta el flujo de caja
resultante para el inversionista.

\begin{table}[htbp]
	\centering
	\caption{Flujo de caja del inversionista (USD).}
	\label{tab:flujo-inversionista}
	\small
	\begin{tblr}{
		colspec = {X[l] r r r r r r},
		row{1} = {font=\bfseries},
		row{9,10} = {font=\bfseries},
				hlines,
			}
		Concepto          & Año 0  & Año 1   & Año 2   & Año 3   & Año 4   & Año 5   \\
		Ingreso total     &        & 25,200  & 26,600  & 28,000  & 29,400  & 30,800  \\
		Costo total       &        & -21,760 & -21,844 & -21,928 & -22,012 & -22,096 \\
		Cuota préstamo    &        & -3,465  & -3,465  & -3,465  & -3,465  & -3,465  \\
		Utilidad neta     &        & -25     & 1,291   & 2,607   & 3,600   & 4,456   \\
		Inversión propia  & -5,530 &         &         &         &         &         \\
		Préstamo recibido & 15,000 &         &         &         &         &         \\
		Valor residual    &        &         &         &         &         & 4,233   \\
		Flujo de caja     & -5,530 & -25     & 1,291   & 2,607   & 3,923   & 5,239   \\
		Acumulado         & -5,530 & -5,555  & -4,263  & -1,656  & 2,268   & 7,507   \\
	\end{tblr}
\end{table}

\subsection{Indicadores financieros}

La Tabla~\ref{tab:indicadores} resume los principales indicadores de
rentabilidad del proyecto.

\begin{table}[htbp]
	\centering
	\caption{Indicadores de rentabilidad del proyecto.}
	\label{tab:indicadores}
	\begin{tblr}{
			colspec = {X[l] r},
			row{1} = {font=\bfseries},
			hlines,
		}
		Indicador                                    & Valor        \\
		TREMA (Tasa de Rendimiento Mínima Aceptable) & 15\%         \\
		TIR (Tasa Interna de Retorno)                & 25\%         \\
		VAN (Valor Actual Neto)                      & 7,517.55 USD \\
		Período de recupero                          & Año 4        \\
	\end{tblr}
\end{table}

Con un VAN positivo de \$7,517.55 y una TIR del 25\% ---superior a la
TREMA del 15\%---, el proyecto resulta \textbf{económicamente viable}.

\section{Análisis de sensibilidad}

Se analizó la sensibilidad del proyecto ante variaciones en las dos
variables más críticas: cantidad de suscripciones anuales y precio
de la suscripción mensual.

\subsection{Sensibilidad a cantidad de suscripciones}

La Tabla~\ref{tab:sens-suscripciones} presenta los valores de TIR y VAN
para diferentes cantidades de suscripciones anuales, manteniendo constantes
las demás variables del modelo.

\begin{table}[htbp]
	\centering
	\caption{Sensibilidad a cantidad de suscripciones anuales.}
	\label{tab:sens-suscripciones}
	\begin{tblr}{
			colspec = {c r r},
			row{1} = {font=\bfseries},
			row{6} = {font=\bfseries},
			hlines,
		}
		Suscripciones/año & TIR   & VAN (USD) \\
		20                & -80\% & -6,373.04 \\
		22                & -35\% & -2,900.39 \\
		24                & -11\% & 572.26    \\
		26                & 8\%   & 4,044.90  \\
		28 (base)         & 25\%  & 7,517.55  \\
		30                & 41\%  & 10,990.20 \\
	\end{tblr}
\end{table}

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
				name=left axis,
				width=0.8\textwidth,
				height=6cm,
				xlabel={Suscripciones anuales},
				ylabel={VAN (USD)},
				axis y line*=left,
				grid=major,
				xmin=18, xmax=32,
				ymin=-8000, ymax=12000,
				xtick={20,22,24,26,28,30},
				scaled ticks=false,
				mark size=3pt,
				legend style={at={(0.02,0.98)}, anchor=north west},
			]
			\addplot[blue, thick, mark=*] coordinates {
					(20, -6373.04)
					(22, -2900.39)
					(24, 572.26)
					(26, 4044.90)
					(28, 7517.55)
					(30, 10990.20)
				};
			\addplot[gray, dashed, thick] coordinates {(18,0) (32,0)};
			\legend{VAN, VAN = 0}
		\end{axis}
		\begin{axis}[
				width=0.8\textwidth,
				height=6cm,
				axis y line*=right,
				axis x line=none,
				ylabel={TIR (\%)},
				ylabel near ticks,
				xmin=18, xmax=32,
				ymin=-100, ymax=50,
				mark size=3pt,
				legend style={at={(0.98,0.02)}, anchor=south east},
			]
			\addplot[red, thick, mark=square*] coordinates {
					(20, -80)
					(22, -35)
					(24, -11)
					(26, 8)
					(28, 25)
					(30, 41)
				};
			\addplot[orange, dashed, thick] coordinates {(18,15) (32,15)};
			\legend{TIR, TREMA (15\%)}
		\end{axis}
	\end{tikzpicture}
	\caption{Sensibilidad del VAN y TIR a la cantidad de suscripciones anuales.}
	\label{fig:sens-suscripciones}
\end{figure}

La Figura~\ref{fig:sens-suscripciones} muestra la relación entre la cantidad
de suscripciones anuales y los indicadores de rentabilidad. Se observa una
relación lineal entre las variables, donde el punto de equilibrio (VAN = 0)
se alcanza con aproximadamente \textbf{24 suscripciones anuales}. El proyecto
supera la TREMA del 15\% a partir de aproximadamente 26 suscripciones anuales.

\subsection{Sensibilidad a precio de suscripción}

La Tabla~\ref{tab:sens-precio} muestra el impacto de variaciones en el
precio mensual de suscripción sobre los indicadores de rentabilidad del
proyecto.

\begin{table}[htbp]
	\centering
	\caption{Sensibilidad al precio mensual de suscripción.}
	\label{tab:sens-precio}
	\begin{tblr}{
			colspec = {c r r},
			row{1} = {font=\bfseries},
			row{6} = {font=\bfseries},
			hlines,
		}
		Precio mensual (USD) & TIR  & VAN (USD) \\
		30                   & -4\% & 2,406.26  \\
		35                   & 5\%  & 3,684.09  \\
		40                   & 12\% & 4,961.91  \\
		45                   & 19\% & 6,239.73  \\
		50 (base)            & 25\% & 7,517.55  \\
		55                   & 30\% & 8,795.37  \\
	\end{tblr}
\end{table}

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
				name=left axis,
				width=0.8\textwidth,
				height=6cm,
				xlabel={Precio mensual (USD)},
				ylabel={VAN (USD)},
				axis y line*=left,
				grid=major,
				xmin=25, xmax=60,
				ymin=0, ymax=10000,
				xtick={30,35,40,45,50,55},
				scaled ticks=false,
				mark size=3pt,
				legend style={at={(0.02,0.98)}, anchor=north west},
			]
			\addplot[blue, thick, mark=*] coordinates {
					(30, 2406.26)
					(35, 3684.09)
					(40, 4961.91)
					(45, 6239.73)
					(50, 7517.55)
					(55, 8795.37)
				};
			\legend{VAN}
		\end{axis}
		\begin{axis}[
				width=0.8\textwidth,
				height=6cm,
				axis y line*=right,
				axis x line=none,
				ylabel={TIR (\%)},
				ylabel near ticks,
				xmin=25, xmax=60,
				ymin=-10, ymax=40,
				mark size=3pt,
				legend style={at={(0.98,0.02)}, anchor=south east},
			]
			\addplot[red, thick, mark=square*] coordinates {
					(30, -4)
					(35, 5)
					(40, 12)
					(45, 19)
					(50, 25)
					(55, 30)
				};
			\addplot[orange, dashed, thick] coordinates {(25,15) (60,15)};
			\legend{TIR, TREMA (15\%)}
		\end{axis}
	\end{tikzpicture}
	\caption{Sensibilidad del VAN y TIR al precio mensual de suscripción.}
	\label{fig:sens-precio}
\end{figure}

La Figura~\ref{fig:sens-precio} ilustra cómo varían el VAN y la TIR en función
del precio mensual de suscripción. Se observa que el proyecto es viable
(TIR $>$ TREMA) a partir de aproximadamente \$43 USD mensuales. El precio
mínimo que mantiene el VAN positivo es cercano a \textbf{\$30 USD mensuales},
aunque la TIR en ese punto sería negativa.

\subsection{Conclusiones del análisis económico}

El análisis demuestra que el emprendimiento es económicamente viable
bajo los supuestos considerados:

\begin{itemize}
	\item El proyecto genera un VAN positivo de \$7,517.55 USD con una
	      TIR del 25\%, superior a la TREMA del 15\%.
	\item El período de recupero de la inversión es de 4 años.
	\item El proyecto tiene margen de seguridad, tolerando una reducción
	      del 14\% en la cantidad de suscripciones (de 28 a 24) antes de
	      volverse inviable.
	\item El precio de suscripción puede reducirse hasta \$40 USD mensuales
	      manteniendo la viabilidad del proyecto.
\end{itemize}

\end{document}